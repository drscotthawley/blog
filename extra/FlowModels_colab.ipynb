{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Flow With What You Know (Colab Version)\n",
        "> Basic physics provides a \"straight, fast\" way to get up to speed with flow-based generative models\n",
        "\n",
        "Author: Scott H. Hawley, Nov 13, 2024"
      ],
      "metadata": {
        "id": "oxHUxNyOna00"
      },
      "id": "oxHUxNyOna00"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preamble:\n",
        "This is the executable version of my blog post [\"Flow With What You Know\"](https://drscotthawley.github.io/blog/posts/FlowModels.html). I think it's easier to read it in blog post form, however to get the full effect you'll want to try swapping out the source & target distributions -- **you don't have to start with gaussian data!**\n",
        "\n",
        "To start, I recommend just going up and choosing `Runtime > Run all` immediately (as in now) before you start reading on. You can always scroll back up and re-run selected parts.  "
      ],
      "metadata": {
        "id": "TwmlPYouqjmn"
      },
      "id": "TwmlPYouqjmn"
    },
    {
      "cell_type": "markdown",
      "id": "e9f0900c-afd8-49d7-9c8b-ecd035ecf6ae",
      "metadata": {
        "id": "e9f0900c-afd8-49d7-9c8b-ecd035ecf6ae"
      },
      "source": [
        "### Abstract\n",
        "\n",
        "In this tutorial post, we provide an accessible introduction to flow-matching and rectified flow models, which are increasingly on the forefront of generative AI applications. Typical descriptions of them are usually laden with extensive probability-math equations, which can form barriers to the dissemination and understanding of these models. Fortunately, before they were couched in probabilities, the mechanisms underlying these models were grounded in basic physics, which provides an alternative and highly-accessible (yet isomorphic) representation of the processes involved. Let's flow."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code: Installs & Imports\n",
        "In this executable version of the notebook, we'll get our installs and imports out of the way.  \n",
        "\n",
        "\n",
        "Much of the code in this lesson is hidden (or collapsed) by default becuase you don't actually need to read it to understand the lesson. (Most of the code is just for plotting figures anyway.) Stil you can always expand the collapsed sections to read as much detail as you want.\n",
        "\n",
        "\n",
        "Note also that this tutorial does not require a GPU runtime; CPU-only is fine for the toy models we'll be using."
      ],
      "metadata": {
        "id": "zk5G0QhMo2Bz"
      },
      "id": "zk5G0QhMo2Bz"
    },
    {
      "cell_type": "code",
      "source": [
        "# On Colab, no need to pip-install these because they're preinstalled\n",
        "#%pip install -Uqq torch numpy matplotlib tqdm"
      ],
      "metadata": {
        "id": "tzmLrq0yosJN"
      },
      "id": "tzmLrq0yosJN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f02637-d71b-47a1-84ea-96e012a102be",
      "metadata": {
        "id": "d0f02637-d71b-47a1-84ea-96e012a102be"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display, clear_output, Image\n",
        "#from tqdm.auto import tqdm   # On Colab, the \"auto\" & \"notebook\" versions don't work but the vanilla version does\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66618af-5be2-47a9-886f-b755cc12878f",
      "metadata": {
        "id": "d66618af-5be2-47a9-886f-b755cc12878f"
      },
      "outputs": [],
      "source": [
        "# Note: for the small toy problem used in this lesson, CPU & GPU performance are about the same.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "print(\"device =\",device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c8fa33-5eaf-45bb-b7ea-46ba11bbe97c",
      "metadata": {
        "id": "78c8fa33-5eaf-45bb-b7ea-46ba11bbe97c"
      },
      "source": [
        "# Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc20704-e538-49ba-9406-14d0345cf95e",
      "metadata": {
        "id": "fcc20704-e538-49ba-9406-14d0345cf95e"
      },
      "source": [
        "\n",
        "Flow-based generative AI models have been gaining significant traction as alternatives or improvements to traditional diffusion approaches in image and audio synthesis. These models excel at learning optimal trajectories for transforming probability distributions, offering a mathematically elegant framework for data generation. The approach has seen renewed momentum following Black Forest Labs' success with their FLUX models [1], spurring fresh interest in the theoretical foundations laid by earlier work on Rectified Flows [2] in ICLR 2023. Improvements such as [3] have even reached the level of state-of-the-art generative models for one or two-step generation.\n",
        "\n",
        "Intuitively, these models operate akin to the fluid processes that transform the shapes of clouds in the sky. While recent expositions [4] have attempted to make these concepts more accessible through probability theory, the underlying physical principles offer a more direct path to understanding.   By returning to the basic physical picture of flows that inspired these generative models, we can build both intuition and deep understanding - insights that may even guide the development of new approaches."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title . (gif embed)\n",
        "HTML(\"\"\"\n",
        "<div class=\"tenor-gif-embed\" data-postid=\"8811006\" data-share-method=\"host\" data-aspect-ratio=\"1.22692\" data-width=\"400px\"><a href=\"https://tenor.com/view/its-black-its-white-michael-jackson-video-gif-8811006\">Its Black Its White Michael Jackson Video GIF</a>from <a href=\"https://tenor.com/search/its+black+its+white-gifs\">Its Black Its White GIFs</a></div> <script type=\"text/javascript\" async src=\"https://tenor.com/embed.js\"></script>\n",
        "<br>\n",
        "Source: Face-morphing example from Michael Jackson's  \"Black Or White\" (1991). <br>\n",
        "Technically not a flow-based generative model[4] but similar enough to use for an intro image. ;-)\n",
        "\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VAdp65wMqMiL"
      },
      "id": "VAdp65wMqMiL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8558083f-5198-46ee-8d2b-41a2c721d8ba",
      "metadata": {
        "id": "8558083f-5198-46ee-8d2b-41a2c721d8ba"
      },
      "source": [
        "## What's a Flow?\n",
        "In the real world, things typically follow curved paths - like water flowing in a river, or crowds of people navigating around obstacles.  Here's map of wind provided from the WW2010 atmospheric science project at UIUC: at every point in space, the wind has a velocity vector, and the air moves along \"streamlines\" or \"trajectories\" parallel to the velocity vectors...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Wind flow map image from the University of Illinois WW2010 Project, http://ww2010.atmos.uiuc.edu/(Gh)/guides/maps/upa/wndvct.rxml](https://i.imgur.com/4Nir9T6.gif)<br>\n",
        "Wind flow map image from the [University of Illinois WW2010 Project](http://ww2010.atmos.uiuc.edu/(Gh)/guides/maps/upa/wndvct.rxml)"
      ],
      "metadata": {
        "id": "h6qtMzUhz7Il"
      },
      "id": "h6qtMzUhz7Il"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notice that the streamlines never cross.  If the streams were to cross... \"it would be bad.\" That would imply that the velocity at some point is undefined."
      ],
      "metadata": {
        "id": "YDMQ5k1SroB3"
      },
      "id": "YDMQ5k1SroB3"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title . (gif embed)\n",
        "HTML(\"\"\"\n",
        "<div class=\"tenor-gif-embed\" data-postid=\"14635781\" data-share-method=\"host\" data-aspect-ratio=\"2.40601\" data-width=\"400px\"><a href=\"https://tenor.com/view/dont-cross-the-streams-ghostbusters-gif-14635781\">Dont Cross The Streams Ghostbusters GIF</a>from <a href=\"https://tenor.com/search/dont+cross+the+streams-gifs\">Dont Cross The Streams GIFs</a></div> <script type=\"text/javascript\" async src=\"https://tenor.com/embed.js\"></script>\n",
        "\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JH-Q8N5wsBwQ"
      },
      "id": "JH-Q8N5wsBwQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "355b6d3f-6c8f-496e-8436-9ef5bca9116c",
      "metadata": {
        "id": "355b6d3f-6c8f-496e-8436-9ef5bca9116c"
      },
      "source": [
        "By the way, this non-crossing property is what allows these flows to be invertible (i.e., reversable), a property you sometimes hear in isolation when reading more formal descriptions of flow models.\n",
        "\n",
        "So at every point in space there's a velocity vector telling the little bits of water where to go. And just like water or wind flows may depend not only on spatial position but also time, so too can our velocity vector field depend on position and time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2dd2e9-48d9-4156-aaff-10072caf2d19",
      "metadata": {
        "id": "3f2dd2e9-48d9-4156-aaff-10072caf2d19"
      },
      "source": [
        "Flow matching learns these natural paths by focusing on the *velocity* at each point - essentially asking \"which way should each point be moving at this moment?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eefdfc95-e02e-4d97-805d-ff99f0314953",
      "metadata": {
        "id": "eefdfc95-e02e-4d97-805d-ff99f0314953"
      },
      "source": [
        "> **Terminology: \"FM/RF\"**\n",
        ">\n",
        "> It may seem confusing to sometimes see \"flow matching\" and \"rectified flows\" being used interchangeably, but this is because they are *the same* [6]. In this blog we'll use the collective term \"FM/RF\" models.\n",
        "> Note that there is no explicit \"rectification\" mechanism in rectified flows; rather any \"rectification\" is a description of the effect of flow-matching, i.e. transforming crossing trajectories to non-crossing ones. The addition of \"Reflow\" to the rectified flow paper [@rectified_flow] is a powerful extension we will cover further below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d705d37-de5c-4888-b5e2-7c2111a2f140",
      "metadata": {
        "id": "8d705d37-de5c-4888-b5e2-7c2111a2f140"
      },
      "source": [
        "# How Do FM/RF Models Work?\n",
        "\n",
        "To gain a deep understanding of how models work, having an executable toy model is often a key instructional tool.  This tutorial is written as a executable Jupyter notebook, though you can make sense of it without the code, so we will typically collapse or hide the code. But if you want to see it, you can expand the drop-down arrows.  \n",
        "\n",
        "For instance, the code starts with importing packages..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d0c3ecb-9ae1-4bb8-9a16-5e347f484abb",
      "metadata": {
        "id": "5d0c3ecb-9ae1-4bb8-9a16-5e347f484abb"
      },
      "source": [
        "**Choose Your Own Data Shapes**\n",
        "\n",
        "The executable verison lets you choose various shapes to \"morph\" between. For this reading, we'll go from a Gaussian to a Spiral:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af7e5535-7705-4399-8ff5-2d51963fed1e",
      "metadata": {
        "id": "af7e5535-7705-4399-8ff5-2d51963fed1e"
      },
      "outputs": [],
      "source": [
        "# Options are: 'Gaussian', 'Square', 'Heart', 'Spiral','Two Gaussians', 'Smiley'\n",
        "source_data_choice = 'Gaussian'\n",
        "target_data_choice = 'Spiral'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3da5cec1-8a68-4e82-9a59-ec7bc6af7b9b",
      "metadata": {
        "id": "3da5cec1-8a68-4e82-9a59-ec7bc6af7b9b"
      },
      "source": [
        "With the imports in place and the choice of starting and ending distributions chosen, we're ready to define some of utilities to generate and visualize our data. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494a821b-466d-4c85-9acd-cbc025fc53e8",
      "metadata": {
        "cellView": "form",
        "id": "494a821b-466d-4c85-9acd-cbc025fc53e8"
      },
      "outputs": [],
      "source": [
        "# @title Utility code: styles, functions, generators, visualization\n",
        "\n",
        "# for accessibility: Wong's color pallette: cf. https://davidmathlogic.com/colorblind\n",
        "#wong_black = [0/255, 0/255, 0/255]          # #000000\n",
        "wong_amber = [230/255, 159/255, 0/255]      # #E69F00\n",
        "wong_cyan = [86/255, 180/255, 233/255]      # #56B4E9\n",
        "wong_green = [0/255, 158/255, 115/255]      # #009E73\n",
        "wong_yellow = [240/255, 228/255, 66/255]    # #F0E442\n",
        "wong_navy = [0/255, 114/255, 178/255]       # #0072B2\n",
        "wong_red = [213/255, 94/255, 0/255]         # #D55E00\n",
        "wong_pink = [204/255, 121/255, 167/255]     # #CC79A7\n",
        "wong_cmap = [wong_amber, wong_cyan, wong_green, wong_yellow, wong_navy, wong_red, wong_pink]\n",
        "\n",
        "source_color = wong_navy\n",
        "target_color = wong_red\n",
        "pred_color = wong_green\n",
        "line_color = wong_yellow\n",
        "bg_theme = 'dark' #  'black', 'white', 'dark', 'light'\n",
        "if bg_theme in ['black','dark']:\n",
        "    plt.style.use('dark_background')\n",
        "else:\n",
        "    plt.rcdefaults()\n",
        "\n",
        "\n",
        "# A few different data distributions\n",
        "def create_gaussian_data(n_points=1000, scale=1.0):\n",
        "    \"\"\"Create a 2D Gaussian distribution\"\"\"\n",
        "    return torch.randn(n_points, 2) * scale\n",
        "\n",
        "def create_square_data(n_points=1000, scale=3.0):  # 3 is set by the spread of the gaussian and spiral\n",
        "    \"\"\"Create points uniformly distributed in a square\"\"\"\n",
        "    # Generate uniform points in a square\n",
        "    points = (torch.rand(n_points, 2) * 2 - 1) * scale\n",
        "    return points\n",
        "\n",
        "def create_spiral_data(n_points=1000, scale=1):\n",
        "    \"\"\"Create a spiral distribution. i like this one more\"\"\"\n",
        "    noise = 0.1*scale\n",
        "    #theta = torch.linspace(0, 6*np.pi, n_points) # preferred order? no way\n",
        "    theta = 6*np.pi* torch.rand(n_points)\n",
        "    r = theta / (2*np.pi) * scale\n",
        "    x = r * torch.cos(theta) + noise * torch.randn(n_points)\n",
        "    y = r * torch.sin(theta) + noise * torch.randn(n_points)\n",
        "    return torch.stack([x, y], dim=1)\n",
        "\n",
        "def create_heart_data(n_points=1000, scale=3.0):\n",
        "    \"\"\"Create a heart-shaped distribution of points\"\"\"\n",
        "    square_points = create_square_data(n_points, scale=1.0)\n",
        "\n",
        "    # Calculate the heart-shaped condition for each point\n",
        "    x, y = square_points[:, 0], square_points[:, 1]\n",
        "    heart_condition = x**2 + ((5 * (y + 0.25) / 4) - torch.sqrt(torch.abs(x)))**2 <= 1\n",
        "\n",
        "    # Filter out points that don't satisfy the heart-shaped condition\n",
        "    heart_points = square_points[heart_condition]\n",
        "\n",
        "    # If we don't have enough points, generate more\n",
        "    while len(heart_points) < n_points:\n",
        "        new_points = create_square_data(n_points - len(heart_points), scale=1)\n",
        "        x, y = new_points[:, 0], new_points[:, 1]\n",
        "        new_heart_condition = x**2 + ((5 * (y + 0.25) / 4) - torch.sqrt(torch.abs(x)))**2 <= 1\n",
        "        new_heart_points = new_points[new_heart_condition]\n",
        "        heart_points = torch.cat([heart_points, new_heart_points], dim=0)\n",
        "\n",
        "    heart_points *= scale\n",
        "    return heart_points[:n_points]\n",
        "\n",
        "def create_two_gaussians_data(n_points=1000, scale=1.0, shift=2.5):\n",
        "    \"\"\"Create a 2D Gaussian distribution\"\"\"\n",
        "    g  = torch.randn(n_points, 2) * scale\n",
        "    g[:n_points//2,0] -= shift\n",
        "    g[n_points//2:,0] += shift\n",
        "    indices = torch.randperm(n_points)\n",
        "    return g[indices]\n",
        "\n",
        "\n",
        "def create_smiley_data(n_points=1000, scale=2.5):\n",
        "    \"make a smiley face\"\n",
        "    points = []\n",
        "    # Face circle\n",
        "    #angles = 2 * np.pi * torch.rand(n_points//2+20)\n",
        "    #r = scale + (scale/10)*torch.sqrt(torch.rand(n_points//2+20))\n",
        "    #points.append(torch.stack([r * torch.cos(angles), r * torch.sin(angles)], dim=1))\n",
        "\n",
        "    # Eyes (small circles at fixed positions)\n",
        "    for eye_pos in [[-1, 0.9], [1, 0.9]]:\n",
        "        eye = torch.randn(n_points//3+20, 2) * 0.2 + torch.tensor(eye_pos) * scale * 0.4\n",
        "        points.append(eye)\n",
        "\n",
        "    # Smile (arc in polar coordinates)\n",
        "    theta = -np.pi/6 - 2*np.pi/3*torch.rand(n_points//3+20)\n",
        "    r_smile = scale * 0.6 + (scale/4)* torch.rand_like(theta)\n",
        "    points.append(torch.stack([r_smile * torch.cos(theta), r_smile * torch.sin(theta)], dim=1))\n",
        "\n",
        "    points = torch.cat(points, dim=0)  # concatenate first\n",
        "    points = points[torch.randperm(points.shape[0])]  # then shuffle\n",
        "    return points[:n_points,:]\n",
        "\n",
        "\n",
        "# Initialize generator functions\n",
        "source_gen_fn = None\n",
        "target_gen_fn = None\n",
        "\n",
        "# Assign generator functions based on user choices\n",
        "for gen_choice, gen_fn_name in zip([source_data_choice, target_data_choice], ['source_gen_fn', 'target_gen_fn']):\n",
        "    gen_choice = gen_choice.lower()\n",
        "    if 'two gaussians' in gen_choice:\n",
        "        gen_fn = create_two_gaussians_data\n",
        "    elif 'heart' in gen_choice:\n",
        "        gen_fn = create_heart_data\n",
        "    elif 'spiral' in gen_choice:\n",
        "        gen_fn = create_spiral_data\n",
        "    elif 'square' in gen_choice:\n",
        "        gen_fn = create_square_data\n",
        "    elif 'smiley' in gen_choice:\n",
        "        gen_fn = create_smiley_data\n",
        "    else:\n",
        "        gen_fn = create_gaussian_data\n",
        "\n",
        "    if gen_fn_name == 'source_gen_fn':\n",
        "        source_gen_fn = gen_fn\n",
        "    else:\n",
        "        target_gen_fn = gen_fn\n",
        "\n",
        "# A couple aliases so we can easily switch distributions without affecting later code\n",
        "def create_source_data(n_points=1000, hshift=0):  # hshift can make it a bit easier to see trajectories later\n",
        "    g = source_gen_fn(n_points=n_points)\n",
        "    if hshift != 0: g[:,0] += hshift\n",
        "    return g\n",
        "\n",
        "def create_target_data(n_points=1000, hshift=0):\n",
        "    g = target_gen_fn(n_points=n_points)\n",
        "    if hshift != 0: g[:,0] += hshift\n",
        "    return g\n",
        "\n",
        "def plot_distributions(dist1, dist2, title1=\"Distribution 1\", title2=\"Distribution 2\", alpha=0.8):\n",
        "    \"\"\"Plot two distributions side by side\"\"\"\n",
        "    plt.close('all')\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    ax1.scatter(dist1[:, 0], dist1[:, 1], alpha=alpha, s=10, color=source_color)\n",
        "    ax2.scatter(dist2[:, 0], dist2[:, 1], alpha=alpha, s=10, color=target_color)\n",
        "\n",
        "    ax1.set_title(title1)\n",
        "    ax2.set_title(title2)\n",
        "\n",
        "    # Set same scale for both plots\n",
        "    max_range = max(\n",
        "        abs(dist1).max().item(),\n",
        "        abs(dist2).max().item()\n",
        "    )\n",
        "    for ax in [ax1, ax2]:\n",
        "        ax.set_xlim(-max_range, max_range)\n",
        "        ax.set_ylim(-max_range, max_range)\n",
        "        ax.set_aspect('equal')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()  # Explicitly show the plot\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def interpolate_color(t, start='blue', end='red'):\n",
        "    \"\"\"Interpolate from matplotlib's default green (t=0) to red (t=1)\"\"\"\n",
        "    start_color = plt.cm.colors.to_rgb(start)\n",
        "    end_color = plt.cm.colors.to_rgb(end)\n",
        "    return (1-t) * np.array(start_color) + t * np.array(end_color)\n",
        "\n",
        "\n",
        "def show_flow_sequence(start_dist, end_dist, n_steps=5, c_start=source_color, c_end=target_color):\n",
        "    \"\"\"Show the flow as a sequence of static plots\"\"\"\n",
        "    fig, axes = plt.subplots(1, n_steps, figsize=(4*n_steps, 4))\n",
        "\n",
        "    max_range = max(\n",
        "        abs(start_dist).max().item(),\n",
        "        abs(end_dist).max().item()\n",
        "    )\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        t = i / (n_steps - 1)\n",
        "        current = start_dist * (1-t) + end_dist * t\n",
        "\n",
        "        color = interpolate_color(t, start=c_start, end=c_end)\n",
        "        ax.scatter(current[:, 0], current[:, 1],\n",
        "                  alpha=0.8, s=10,\n",
        "                  c=[color])\n",
        "\n",
        "        ax.set_xlim(-max_range, max_range)\n",
        "        ax.set_ylim(-max_range, max_range)\n",
        "        ax.set_aspect('equal')\n",
        "        ax.set_title(f't = {t:.2f}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "# Create our distributions and look at them\n",
        "n_points = 1000\n",
        "source, target = create_source_data(n_points), create_target_data(n_points)\n",
        "\n",
        "plot_distributions(source, target, \"Starting Distribution\", \"Target Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c3d0b37-2947-4267-a422-4b0ddfe3e735",
      "metadata": {
        "id": "0c3d0b37-2947-4267-a422-4b0ddfe3e735"
      },
      "source": [
        "The process of transition from the starting \"source\" to the final \"target\" might include snapshots like these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0211557-b812-4df0-8214-47821fb32349",
      "metadata": {
        "id": "f0211557-b812-4df0-8214-47821fb32349"
      },
      "outputs": [],
      "source": [
        "show_flow_sequence(source, target, n_steps=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00bb7f60-f91d-4b97-a912-ea79af276373",
      "metadata": {
        "id": "00bb7f60-f91d-4b97-a912-ea79af276373"
      },
      "source": [
        "(Note the colors aren't meaningful, they're just added to make it easier to distinguish what we're looking at. Our data are just points in 2-D space.)\n",
        "\n",
        "<!---Here's an animation with no colors, showing the points moving. ... --->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de46da28-e507-4930-9ca7-2203a8d04313",
      "metadata": {
        "id": "de46da28-e507-4930-9ca7-2203a8d04313"
      },
      "source": [
        "So, how do we get the points from the source distribution to fit with the target distribution? The simplest way (though not the only way) is to assume points move in straight lines from source to target. Even though our network might learn more complex paths later, this gives us a starting point for training.\n",
        "\n",
        "## The Starting Setup\n",
        "The training setup for flow matching models is as follows:\n",
        "1. We start by *randomly pairing* points from the source & the target -- yes, really. :rofl:\n",
        "2. We move the points along straight trajectories, and the speed of each point is constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf68268-ed71-491a-b90b-45d5e559f6df",
      "metadata": {
        "cellView": "form",
        "id": "dbf68268-ed71-491a-b90b-45d5e559f6df"
      },
      "outputs": [],
      "source": [
        "# @title Code for 2D flow-matching diagram with crossing lines\n",
        "#| code-fold: true\n",
        "source_L = source.clone()\n",
        "shift = 5\n",
        "source_L[:,0] -= shift\n",
        "target_R = target.clone()\n",
        "target_R[:,0] += shift  # Note: fixed the indexing here from [:0] to [:,0]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "# show the whole distribution\n",
        "ax.scatter(source_L[:,0], source_L[:,1], color=source_color, alpha=0.5)\n",
        "ax.scatter(target_R[:,0], target_R[:,1], color=target_color, alpha=0.5)\n",
        "\n",
        "# Draw lines connecting points, with source & target points outlined\n",
        "n_lines = 15\n",
        "ax.scatter(source_L[:n_lines,0], source_L[:n_lines,1], color=source_color, alpha=0.5,\n",
        "           facecolor='none', edgecolor=line_color,)\n",
        "ax.scatter(target_R[:n_lines,0], target_R[:n_lines,1], color=target_color, alpha=0.5,\n",
        "           facecolor='none', edgecolor=line_color,)\n",
        "for i in range(n_lines):\n",
        "    ax.plot([source_L[i,0], target_R[i,0]],\n",
        "        [source_L[i,1], target_R[i,1]],\n",
        "        '-', alpha=0.3, color=line_color+[.9],\n",
        "        linewidth=2)  # or lw=2\n",
        "\n",
        "ax.set_aspect('equal')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "for [x, label] in zip([-shift,shift], ['Source','Target']):\n",
        "    ax.text(x, 4, label, fontsize=12, color='black', ha='center',  va='center',)\n",
        "plt.show()\n",
        "os.makedirs('images', exist_ok=True)\n",
        "save_file='images/gaussian_to_spiral_crossing_lines.png'\n",
        "plt.savefig(save_file)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431d14e3-9bbc-4aa4-bdd8-1d0b06387fc8",
      "metadata": {
        "id": "431d14e3-9bbc-4aa4-bdd8-1d0b06387fc8"
      },
      "source": [
        "There are big issues with doing this: The random pairing results in lots of trajectories that cross each other. But this is a *starting point* for Flow Matching.  So in other words, when training a Flow Matching model...\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title . (gif embed)\n",
        "HTML(\"\"\"\n",
        "<img src=\"https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExNm4yN3J1MXhlYWVnNGJ5MWk5enF0bDdxcmhuaHc4b3Awbmh6ZDRqayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o72EWUgbRNfLegO1W/giphy.gif\">\"\n",
        "\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-wJn83KWs2a5"
      },
      "id": "-wJn83KWs2a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "987c16e1-47ea-44cb-a16e-27333d4485e1",
      "metadata": {
        "id": "987c16e1-47ea-44cb-a16e-27333d4485e1"
      },
      "source": [
        "...well, ok not quite: we're going to allow the *trajectories of individual points* to cross as we train the model. This *is* a bit \"confusing\" for the model, which will be trying to learn a velocity field, and that isn't defined where trajectories cross. Eventually, however, the model will learn to estimate the *aggregated motion* of many particles, which will sort of average out to arrive at the \"bulk motion\" of the flow. This is similar to how the Brownian motion [7] of many air or water particles averages out on the macroscopic level, giving us streamlines that don't cross.[^1]\n",
        "\n",
        "[^1]: A related example from science fiction: in the fictitous \"psychohistory\" theory in Isaac Asimov's *Foundation* series, the individual choices and \"trajectories\" of individual people can't be predicted, but the aggregated motion of an entire society follows predictable paths.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c224147e-7e49-42ae-839d-16abb3cf3528",
      "metadata": {
        "id": "c224147e-7e49-42ae-839d-16abb3cf3528"
      },
      "source": [
        "This is why flow matching is about transforming *distributions*, not individual points. The learned velocity field might not exactly match any of our training trajectories, but it captures the statistical flow needed to transform one distribution into another.\n",
        "\n",
        "Here's a visualization from the code we'll execute later in the lesson. We'll plot...\n",
        "\n",
        "1. Our naive training trajectories (with crossings)\n",
        "2. The actual learned flow field\n",
        "3. The paths points take when following the learned field"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cross-uncross-plot](https://i.imgur.com/ZXIRlE1.png)"
      ],
      "metadata": {
        "id": "6pwa3mi1tL16"
      },
      "id": "6pwa3mi1tL16"
    },
    {
      "cell_type": "markdown",
      "id": "66c9ff3d-1f1d-4087-8314-65a06fbac2f3",
      "metadata": {
        "id": "66c9ff3d-1f1d-4087-8314-65a06fbac2f3"
      },
      "source": [
        "![](images/cross_uncross_plot.png)\n",
        "Left: Training data uses simple straight lines (with many crossings).\n",
        "Middle: The learned flow (velocity vector) field is smooth and continuous.\n",
        "Right: Actual trajectories following the flow field don't cross."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dacbf80b-5fa3-47ea-963d-b11baae9f2f0",
      "metadata": {
        "id": "dacbf80b-5fa3-47ea-963d-b11baae9f2f0"
      },
      "source": [
        "## How Are Flows 'Learned'?\n",
        "\n",
        "The goal of the macahine learning system is as follows: for any point in space and any time t between 0 and 1, we want to learn the correct *velocity* (direction and speed) that point should move.  It's like learning the \"wind map\" that will blow the starting distribution cloud into the shape of the target distribution cloud.\n",
        "\n",
        "Since neural networks are such useful engines for approximation and interpolation, we'll let a neural network \"learn\" to estimate the mapping between locations and times (as inputs), and velocities (as outputs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "437d8fab-9aa1-4642-8f66-f04d2e3938d2",
      "metadata": {
        "id": "437d8fab-9aa1-4642-8f66-f04d2e3938d2"
      },
      "source": [
        "> **Terminology: \"Simulation Free\"**\n",
        ">\n",
        "> You'll sometimes see flow-maching models being referred to as \"simulation free.\"  This just an indication that the flow we arrive is not the result of any explicit simulation of any process (physical or otherwise).  The flow obtained arises simply from the aggregation of many particles moving along imagined straight lines and  crossing paths."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8cce90-d4cf-4489-adac-67cae27fe9d2",
      "metadata": {
        "id": "8b8cce90-d4cf-4489-adac-67cae27fe9d2"
      },
      "source": [
        "### The Neural Network's Job\n",
        "\n",
        "The neural network has one job: given a position in space and a time, to output a velocity vector.  *That's all it does.*  Below is the code for this model that will \"learn\" to estimate velocity vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a22fdf8-2b73-4045-a46a-4459ad3b4888",
      "metadata": {
        "id": "6a22fdf8-2b73-4045-a46a-4459ad3b4888"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VelocityNet(nn.Module):\n",
        "    def __init__(self, input_dim, h_dim=64):\n",
        "        super().__init__()\n",
        "        self.fc_in  = nn.Linear(input_dim + 1, h_dim)\n",
        "        self.fc2    = nn.Linear(h_dim, h_dim)\n",
        "        self.fc3    = nn.Linear(h_dim, h_dim)\n",
        "        self.fc_out = nn.Linear(h_dim, input_dim)\n",
        "\n",
        "    def forward(self, x, t, act=F.gelu):\n",
        "        t = t.expand(x.size(0), 1)  # Ensure t has the correct dimensions\n",
        "        x = torch.cat([x, t], dim=1)\n",
        "        x = act(self.fc_in(x))\n",
        "        x = act(self.fc2(x))\n",
        "        x = act(self.fc3(x))\n",
        "        return self.fc_out(x)\n",
        "\n",
        "# Instantiate the model\n",
        "input_dim = 2\n",
        "model = VelocityNet(input_dim)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc88556-2509-4fa4-a618-9bba007f2005",
      "metadata": {
        "id": "3dc88556-2509-4fa4-a618-9bba007f2005"
      },
      "source": [
        "...That's it!  Looks pretty simple, right?  That's because to make the system work we'll need more than just the velocity field model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df7f8f2e-13ca-4b30-8b9b-a31d20d2b933",
      "metadata": {
        "id": "df7f8f2e-13ca-4b30-8b9b-a31d20d2b933"
      },
      "source": [
        "Apart from the velocity model (i.e., the neural network, for us), the rest of the software system then uses these generated velocities to move points around. The model's velocities are then used in a differential equation describing the small change each particle's position $\\vec{r}$ over a short time:\n",
        "\n",
        "$$ d\\vec{r} = v(\\vec{r},t) dt$$\n",
        "\n",
        "The is integrated by some  (totally separate) numerical integration routine. A popular choice in the machine learning world is the \"forward Euler\" method, which is simple to implement, but will need to be upgraded (see furter below) to get good results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8d3d5d-a7cd-4b72-b569-e994e4d4b56b",
      "metadata": {
        "id": "df8d3d5d-a7cd-4b72-b569-e994e4d4b56b"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def fwd_euler_step(model, current_points, current_t, dt):\n",
        "    velocity = model(current_points, current_t)\n",
        "    return current_points + velocity * dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6fba630-76da-4a98-b9f9-2286d563b5dd",
      "metadata": {
        "cellView": "form",
        "id": "e6fba630-76da-4a98-b9f9-2286d563b5dd"
      },
      "outputs": [],
      "source": [
        "# @title Integrator code: generate/predict samples using the trained model\n",
        "@torch.no_grad()\n",
        "def integrate_path(model, initial_points, step_fn=fwd_euler_step, n_steps=100,\n",
        "                   save_trajectories=False, warp_fn=None):\n",
        "    \"\"\"this 'sampling' routine is primarily used for visualization.\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    current_points = initial_points.clone()\n",
        "    ts =  torch.linspace(0,1,n_steps).to(device)\n",
        "    if warp_fn: ts = warp_fn(ts)\n",
        "    if save_trajectories: trajectories = [current_points]\n",
        "    for i in range(len(ts)-1):\n",
        "        current_points = step_fn(model, current_points, ts[i], ts[i+1]-ts[i])\n",
        "        if save_trajectories: trajectories.append(current_points)\n",
        "    if save_trajectories: return current_points, torch.stack(trajectories).cpu()\n",
        "    return current_points\n",
        "\n",
        "generate_samples = integrate_path # just lil' alias for the probability / diffusion model crowd ;-)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27467b98-094e-45e1-9cc3-5afa5df32404",
      "metadata": {
        "id": "27467b98-094e-45e1-9cc3-5afa5df32404"
      },
      "source": [
        "## Training Code\n",
        "The goal of the training code is twofold:\n",
        "1. to expose the model as many locations and times as possible -- at least for those times & locations that \"matter most\". This exposure is what I'll refer to as \"coverage\".\n",
        "2. to force it to learn to generate (approximately) correct velocities at those times and locations.\n",
        "\n",
        "That's it.  The training code doesn't actually do any integration or solving, but we'll typically execute the integration just to visualize \"how we're doing\" as the training progresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fbbd11-2c8f-4d1d-a0f6-9de17f48d9a1",
      "metadata": {
        "cellView": "form",
        "id": "51fbbd11-2c8f-4d1d-a0f6-9de17f48d9a1"
      },
      "outputs": [],
      "source": [
        "# @title Viz code: calls integrator to calc motion given v field, makes pictures\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Viz code: calls integrator to calc motion given v field, makes pictures\"\n",
        "\n",
        "def viz(val_points, target_samples, trained_model, size=20, alpha=0.5, n_steps=100, warp_fn=None,):\n",
        "    # Generate and visualize new samples\n",
        "    device = next(trained_model.parameters()).device\n",
        "    generated_samples, trajectories = integrate_path(trained_model, val_points.to(device), n_steps=n_steps, warp_fn=warp_fn, save_trajectories=True)\n",
        "\n",
        "    n_viz = min(30, len(trajectories[0]))  # Number of trajectories to visualize\n",
        "\n",
        "    fig, ax = plt.subplots(1,4, figsize=(13,3))\n",
        "    data_list = [val_points.cpu(), generated_samples.cpu(), target_samples.cpu()]\n",
        "    label_list = ['Initial Points', 'Generated Samples', 'Target Data','Trajectories']\n",
        "    color_list = [source_color, pred_color, target_color]\n",
        "    global_max = max( torch.max(torch.abs(torch.cat(data_list)),0)[0][0],  torch.max(torch.abs(torch.cat(data_list)),0)[0][1] )\n",
        "    for i in range(len(label_list)):\n",
        "        ax[i].set_title(label_list[i])\n",
        "        ax[i].set_xlim([-global_max, global_max])\n",
        "        ax[i].set_ylim([-global_max, global_max])\n",
        "        if i < 3: # non-trajectory plots\n",
        "            ax[i].scatter( data_list[i][:, 0], data_list[i][:, 1], s=size, alpha=alpha,\n",
        "                          label=label_list[i], color=color_list[i])\n",
        "        else:\n",
        "            # Plot trajectory paths first\n",
        "            for j in range(n_viz):\n",
        "                path = trajectories[:, j]\n",
        "                ax[3].plot(path[:, 0], path[:, 1], '-', color=line_color, alpha=1, linewidth=1)\n",
        "\n",
        "            # Then plot start and end points for the SAME trajectories\n",
        "            start_points = trajectories[0, :n_viz]\n",
        "            end_points = trajectories[-1, :n_viz]\n",
        "            ax[3].scatter(start_points[:, 0], start_points[:, 1], color=source_color, s=size, alpha=1, label='Source Points')\n",
        "            ax[3].scatter(end_points[:, 0], end_points[:, 1], color=pred_color, s=size, alpha=1, label='Current Endpoints')\n",
        "            ax[3].legend()\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Visualize the data\n",
        "n_samples = 1000\n",
        "source_samples = create_source_data(n_samples)\n",
        "target_samples = create_target_data(n_samples)\n",
        "val_points = create_source_data(n_samples)\n",
        "print(\"Testing visualization routines (before training):\")\n",
        "viz(val_points, target_samples,  model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08b38ec-da42-48d3-8b78-da057be9601c",
      "metadata": {
        "id": "e08b38ec-da42-48d3-8b78-da057be9601c"
      },
      "source": [
        "The clever part about flow matching is how we train this network. For each training step:\n",
        "\n",
        "1. Sample random points from our source distribution\n",
        "2. Sample random time points between 0 and 1\n",
        "3. Calculate where these points *should* be at those times (we'll see how in a moment)\n",
        "4. Calculate what velocity they *should* have at those times\n",
        "5. Train the network to predict these velocities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a2b538-f426-4b68-ae0a-c72d31ffa33d",
      "metadata": {
        "cellView": "form",
        "id": "21a2b538-f426-4b68-ae0a-c72d31ffa33d"
      },
      "outputs": [],
      "source": [
        "# @title Code for train_model() training loop\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Code for train_model() training loop\"\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, n_epochs=100, lr=0.003, batch_size=2048, status_every=1, viz_every=1, warp_fn=None):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    step, n_steps = 0, 100\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        pbar = tqdm(range(n_steps), leave=False)\n",
        "        for _ in pbar:\n",
        "            step += 1\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # by randomly generating new data each step, we prevent the model from merely memorizing\n",
        "            source_samples = create_source_data(batch_size).to(device)\n",
        "            target_samples = create_target_data(batch_size).to(device)\n",
        "\n",
        "            t = torch.rand(source_samples.size(0), 1).to(device)  # random times for traning\n",
        "            if warp_fn: t = warp_fn(t)    # time warp is good for coverage but not as helpful for training as it is during integration/sampling\n",
        "            interpolated_samples = source_samples * (1 - t) + target_samples * t\n",
        "            line_directions = target_samples - source_samples\n",
        "\n",
        "            drift = model(interpolated_samples, t)\n",
        "            loss = loss_fn(drift, line_directions)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            status_str = f'Epoch [{epoch + 1}/{n_epochs}], Loss: {loss.item():.4f}'\n",
        "            pbar.set_description(status_str) # colab not showing any progress bar???\n",
        "\n",
        "        if (epoch + 1) % viz_every == 0:\n",
        "            model.eval()\n",
        "            clear_output(wait=True)  # Clear previous plots\n",
        "            viz(val_points, target_samples[:val_points.shape[0]], model)\n",
        "            plt.show()\n",
        "            plt.close()  # Close the figure to free memory\n",
        "            model.train()\n",
        "\n",
        "        if epoch==n_epochs-1: print(status_str)  # keep last status from being cleared\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90766b72-2c37-4a66-a4bd-1ca9fdda5a23",
      "metadata": {
        "id": "90766b72-2c37-4a66-a4bd-1ca9fdda5a23"
      },
      "outputs": [],
      "source": [
        "fm_model = train_model(model, n_epochs=100)     # Run traiing; this will take a couple minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a03aff-e9d9-4841-aef7-c93caa52bddf",
      "metadata": {
        "id": "a6a03aff-e9d9-4841-aef7-c93caa52bddf"
      },
      "source": [
        "Here's an animation of our model integrating the flow from start to finish:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3779898e-1a63-4a8b-a4b0-cbcdb4ef4e31",
      "metadata": {
        "cellView": "form",
        "id": "3779898e-1a63-4a8b-a4b0-cbcdb4ef4e31"
      },
      "outputs": [],
      "source": [
        "# @title Code for animating points in flow\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Code for animating points in flow\"\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML, display, clear_output\n",
        "from matplotlib import rc\n",
        "import os\n",
        "\n",
        "@torch.no_grad()\n",
        "def create_flow_animation(start_dist, models, titles=None, figsize=None, n_frames=50,\n",
        "                         step_fn=fwd_euler_step, n_steps=100, warp_fn=None, save_file=None, height=4):\n",
        "    \"\"\"\n",
        "    Create an animation showing multiple distribution flows\n",
        "\n",
        "    Args:\n",
        "        start_dist: Starting distribution\n",
        "        models: List of models to animate\n",
        "        titles: List of titles for each subplot (optional)\n",
        "        figsize: Figure size (optional)\n",
        "        n_frames: Number of animation frames\n",
        "        integrator: Integration function to use\n",
        "        jitter: Amount of jitter to add\n",
        "        save_file: Path to save animation (optional)\n",
        "        height: Height of each subplot\n",
        "    \"\"\"\n",
        "    plt.close('all')  # Close all open figures\n",
        "\n",
        "    if not isinstance(models, list): models = [models]\n",
        "    n_plots = len(models)\n",
        "\n",
        "    if titles is None:\n",
        "        titles = [f'Flow {i+1}' for i in range(n_plots)]\n",
        "    elif len(titles) != n_plots:\n",
        "        raise ValueError(f\"Number of titles ({len(titles)}) must match number of models ({n_plots})\")\n",
        "\n",
        "    # Calculate figure size\n",
        "    if figsize is None:\n",
        "        figsize = [height * n_plots, height]\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(1, n_plots, figsize=figsize)\n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "    plt.close()  # Close the figure immediately\n",
        "\n",
        "\n",
        "    # Initialize scatters and trajectories\n",
        "    scatters = []\n",
        "    all_trajectories = []\n",
        "\n",
        "    # Generate trajectories for each model\n",
        "    max_range = abs(start_dist).max().item()\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        device = next(model.parameters()).device\n",
        "        end_dist, trajectories = integrate_path(model, start_dist.clone().to(device), n_steps=n_frames,\n",
        "                                          step_fn=step_fn, warp_fn=warp_fn, save_trajectories=True)\n",
        "        all_trajectories.append(trajectories.cpu())\n",
        "        scatters.append(axes[i].scatter([], [], alpha=0.6, s=10, color=wong_pink))\n",
        "\n",
        "        # Update max range\n",
        "        max_range = max(max_range, abs(end_dist.cpu()).max().item())\n",
        "\n",
        "    # Set up axes\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.set_xlim((-max_range, max_range))\n",
        "        ax.set_ylim((-max_range, max_range))\n",
        "        ax.set_aspect('equal')\n",
        "        ax.set_xticks([])\n",
        "        for spine in ['top', 'right', 'bottom', 'left']:\n",
        "            ax.spines[spine].set_visible(False)\n",
        "        ax.set_title(titles[i])\n",
        "\n",
        "    def init():\n",
        "        \"\"\"Initialize animation\"\"\"\n",
        "        for scatter in scatters:\n",
        "            scatter.set_offsets(np.c_[[], []])\n",
        "        return tuple(scatters)\n",
        "\n",
        "    def animate(frame):\n",
        "        \"\"\"Update animation frame\"\"\"\n",
        "        # Update axis limits (in case they need to be adjusted)\n",
        "        for ax in axes:\n",
        "            ax.set_xlim((-max_range, max_range))\n",
        "            ax.set_ylim((-max_range, max_range))\n",
        "\n",
        "        # Update scatter positions\n",
        "        for scatter, trajectories in zip(scatters, all_trajectories):\n",
        "            scatter.set_offsets(trajectories[frame].numpy())\n",
        "\n",
        "        return tuple(scatters)\n",
        "\n",
        "    # Create animation\n",
        "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                                 frames=n_frames, interval=20, blit=True)\n",
        "\n",
        "    # Handle saving or displaying\n",
        "    if save_file:\n",
        "        os.makedirs(os.path.dirname(save_file), exist_ok=True)\n",
        "        anim.save(save_file, writer='ffmpeg', fps=30)\n",
        "        return HTML(f\"\"\"<center><video height=\"350\" controls loop><source src=\"{anim_file}\" type=\"video/mp4\">\n",
        "              Your browser does not support the video tag. </video></center>\"\"\")\n",
        "    else:  # direct matplotlib anim offers better controls but makes ipynb file size huge\n",
        "        rc('animation', html='jshtml')\n",
        "        return HTML(anim.to_jshtml())\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "#anim_file = 'images/particles_fm.mp4'\n",
        "create_flow_animation(val_points.clone(), models=[fm_model], titles=['Flow Matching'],\n",
        "                      n_frames=50, save_file=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2760fd7e-a62d-44bc-b144-f1fd48df8c18",
      "metadata": {
        "id": "2760fd7e-a62d-44bc-b144-f1fd48df8c18"
      },
      "source": [
        "So, even though we trained using trajectories that crossed, what the model learned were non-crossing (but curvy!) trajectories. Here's a static plot of these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97abcfcc-85a6-4907-9686-126a44755f49",
      "metadata": {
        "cellView": "form",
        "id": "97abcfcc-85a6-4907-9686-126a44755f49"
      },
      "outputs": [],
      "source": [
        "# @title Code to plot initial crossing trajectories vs. learned flow\n",
        "\n",
        "@torch.no_grad()\n",
        "def plot_training_trajectories_vs_learned_flow(model):\n",
        "   \"\"\"Compare training trajectories with learned flow field\"\"\"\n",
        "   plt.figure(figsize=(15, 5))\n",
        "\n",
        "   # 1. Plot some training trajectories\n",
        "   plt.subplot(131)\n",
        "   n_trajs = 50  # Number of trajectories to show\n",
        "   device = next(model.parameters()).device\n",
        "   source = create_gaussian_data(n_trajs)\n",
        "   target = create_square_data(n_trajs)\n",
        "   current_points = source.clone().to(device)\n",
        "\n",
        "\n",
        "   # Plot straight-line trajectories from source to target\n",
        "   times = torch.linspace(0, 1, 20)\n",
        "   for i in range(n_trajs):\n",
        "       traj = source[i:i+1] * (1 - times.reshape(-1, 1)) + target[i:i+1] * times.reshape(-1, 1)\n",
        "       plt.plot(traj[:, 0], traj[:, 1], 'b-', alpha=0.6, linewidth=3)\n",
        "   plt.title('Training Trajectories\\n(with crossings)')\n",
        "   plt.axis('equal')\n",
        "\n",
        "   # 2. Plot learned flow field\n",
        "   plt.subplot(132)\n",
        "   x = torch.linspace(-3, 3, 20)\n",
        "   y = torch.linspace(-3, 3, 20)\n",
        "   X, Y = torch.meshgrid(x, y, indexing='ij')\n",
        "   points = torch.stack([X.flatten(), Y.flatten()], dim=1).to(device)\n",
        "\n",
        "   # with torch.no_grad():\n",
        "   #     t =  0.5  # Show flow field at t=0.5\n",
        "   #     ones = torch.ones(points.size(0), 1)\n",
        "\n",
        "   ones = torch.ones(points.size(0), 1).to(device)\n",
        "   t = ones * (0.5)\n",
        "   velocities = model(points, t).cpu()\n",
        "   #print(\"points.shape, ones.shape = \",points.shape, ones.shape)\n",
        "   #velocities = model(points, t*ones)\n",
        "   points = points.cpu()\n",
        "   plt.quiver(points[:, 0], points[:, 1],\n",
        "             velocities[:, 0], velocities[:, 1],\n",
        "             alpha=0.5, color=line_color, linewidth=3)\n",
        "   plt.title('Learned Flow Field\\nat t=0.5')\n",
        "   plt.axis('equal')\n",
        "\n",
        "   # 3. Plot actual paths taken using learned flow\n",
        "   plt.subplot(133)\n",
        "   source = create_gaussian_data(n_trajs)\n",
        "\n",
        "   # Use RK4 to follow the learned flow\n",
        "   paths = []\n",
        "   n_steps = 20\n",
        "   dt = 1.0 / n_steps\n",
        "\n",
        "   with torch.no_grad():\n",
        "       ones = torch.ones(current_points.size(0), 1).to(device)\n",
        "       for i in range(n_steps):\n",
        "           paths.append(current_points.clone())\n",
        "\n",
        "           # RK4 step\n",
        "           t = ones * (i * dt)\n",
        "           k1 = model(current_points, t)\n",
        "           k2 = model(current_points + k1 * dt/2, t + dt/2)\n",
        "           k3 = model(current_points + k2 * dt/2, t + dt/2)\n",
        "           k4 = model(current_points + k3 * dt, t + dt)\n",
        "\n",
        "           current_points = current_points + (k1 + 2*k2 + 2*k3 + k4) * dt/6\n",
        "\n",
        "   paths = torch.stack(paths).cpu()\n",
        "\n",
        "   # Plot the actual paths\n",
        "   for i in range(n_trajs):\n",
        "       traj = paths[:, i, :]\n",
        "       plt.plot(traj[:, 0], traj[:, 1], color=line_color, alpha=0.5, linewidth=3)\n",
        "   plt.title('Actual Paths\\nFollowing Learned Flow')\n",
        "   plt.axis('equal')\n",
        "\n",
        "   plt.tight_layout()\n",
        "   plt.savefig('images/cross_uncross_plot.png')\n",
        "   plt.show()\n",
        "   plt.close()\n",
        "\n",
        "# Run the visualization\n",
        "plot_training_trajectories_vs_learned_flow(fm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d2a400-6d26-4908-8851-68a49f5233cf",
      "metadata": {
        "id": "06d2a400-6d26-4908-8851-68a49f5233cf"
      },
      "source": [
        "...So we see that even though the model was trained using lots of crossing paths, it learned a smooth flow from them!\n",
        "\n",
        "Even though the trajectories on the right are smooth and non-crossing, their curviness means that we need to integrate slowly and carefully to avoid accruing significant error.  Good news: the \"Rectified Flow\" paper of Liu et al [2] offers a powerful way to speed up the integration by \"straightening\" the curved trajectories, a method they call \"Reflow.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c163f31-abea-48c4-bb7f-b72d1e2f4df6",
      "metadata": {
        "id": "6c163f31-abea-48c4-bb7f-b72d1e2f4df6"
      },
      "source": [
        "# \"Reflow\" to Go Straighter & Faster\n",
        "\n",
        "The Reflow idea is that, instead of randomly pairing source and target points when choose straight trajectories, we use \"simulated target points\" by integrating the source points forward using the learned flow model. Then we use those endpoints as the targets and assume linear motion as before.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4057c69-2ea3-4b97-9150-d380e5640c83",
      "metadata": {
        "id": "e4057c69-2ea3-4b97-9150-d380e5640c83"
      },
      "source": [
        "![reflow_diagram.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d558c78a-b9b9-4554-a3ec-3fac64c95f6c",
      "metadata": {
        "id": "d558c78a-b9b9-4554-a3ec-3fac64c95f6c"
      },
      "source": [
        "This has the effect of straightening out the curved trajectory of the flow matching model, making the new \"reflowed\" trajectories much easier and faster to integrate!\n",
        "\n",
        "Essentially, Reflow is a \"teacher-student\" paradigm in which the (pre-)trained flow-matching model is the teacher, and new Reflowed model is the student. One can also think of this as a kind of distillation, akin to \"consistency models\" [@consistency_models].\n",
        "\n",
        "\n",
        "Before we can rely on those integrated endpoints, we should make a couple improvements to how we use the model we just trained."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64fc435-4280-4320-80b3-a982426ea547",
      "metadata": {
        "id": "f64fc435-4280-4320-80b3-a982426ea547"
      },
      "source": [
        "## Upgrading Our Gear First\n",
        "Neither of these upgrades require to retraining the model. The just help to make efficient, accurate use of it so we can use it as an effective \"teacher\" to the \"student\" reflow model we'll train below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba290cfd-e88b-4f49-afbe-730f1ff929ef",
      "metadata": {
        "id": "ba290cfd-e88b-4f49-afbe-730f1ff929ef"
      },
      "source": [
        "### More Points Where Needed (via Time Warping)\n",
        "\n",
        "You'll notice that trajectories are sharply curved in the middle, but are straight near the start and end. Just as you'd slow down when driving around a sharp turn, we should take smaller integration steps in these curved regions for accuracy.\n",
        "\n",
        "This idea of non-uniform temporal sampling appears throughout generative models. Esser et al.'s \"FLUX\" paper specifically designs their sampling distribution to concentrate points in the middle of the integration where accuracy is most crucial. The same principle applies here: during training, we need good coverage where the model needs to make careful predictions, and during inference, high-curvature regions require denser sampling.\n",
        "\n",
        "One handy S-shaped time-warping function is this polynomial that lets us vary the concentration of points[^2]:\n",
        "\n",
        "$$ f(t) =  4(1-s)t^3 + 6(s-1) t^2 + (3-2s)t, \\ \\ \\ \\ \\ \\  t\\in[0,1], \\ \\ \\ s\\in[0,3/2] $$\n",
        "\n",
        "[^2]: Note: my $f(t)$ is a close approximation to the \"mode function\" Eq. 20 in <a href=\"https://arxiv.org/abs/2403.03206\">Esser et al</a>, with their $s$ being about (1.75 - $s_{\\rm mine}$), and with $t\\rightarrow 1-t$.  My blue line is right underneath their purple line in the Desmos graph below -- I didn't plan that, just similar minds at work!  Both our curves can do the Karras et al cosine schedule, shown in green in the the Desmos figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f90c690-604d-4af0-bd70-b5501f649f9b",
      "metadata": {
        "cellView": "form",
        "id": "8f90c690-604d-4af0-bd70-b5501f649f9b"
      },
      "outputs": [],
      "source": [
        "# @title . (embed Desmos animation)\n",
        "#| echo: false\n",
        "# Jupyter's markdown won't perform the iframe embed unless we \"execute\" the HTML code??\n",
        "HTML(\"\"\"\n",
        "<center>\n",
        "<a href=\"https://www.desmos.com/calculator/g6ffbljlng\">\n",
        "<iframe src=\"https://www.desmos.com/calculator/hfjxlwycmz?embed\" width=\"225\" height=\"225\" style=\"border: 1px solid #ccc\" frameborder=0></iframe>\n",
        "<br>Interactive Desmos Graph Link</a>\n",
        "<br><br>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a874a013-7cf3-41c3-93b6-eccd3dac92c3",
      "metadata": {
        "id": "a874a013-7cf3-41c3-93b6-eccd3dac92c3"
      },
      "source": [
        "The parameter $s$ is the slope at t=1/2, and controls where points concentrate: values between 0 and 1 give us more points in the middle, which is exactly what we want for these curved trajectories. The value $s=0.5$ is a good choice, as we'll see shortly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c9358b-2ba8-4b9c-a257-70ab8a4cd081",
      "metadata": {
        "id": "60c9358b-2ba8-4b9c-a257-70ab8a4cd081"
      },
      "source": [
        "This approach can improve accuracy and/or require fewer total integration steps. Let's look at the results of different amounts of time-warping around a simple parabola:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389b23ba-bbcf-4ce8-aa52-3d32b219aa47",
      "metadata": {
        "cellView": "form",
        "id": "389b23ba-bbcf-4ce8-aa52-3d32b219aa47"
      },
      "outputs": [],
      "source": [
        "# @title Code for warp_time function\n",
        "def warp_time(t, dt=None, s=.5):\n",
        "    \"\"\"Parametric Time Warping: s = slope in the middle.\n",
        "        s=1 is linear time, s < 1 goes slower near the middle, s>1 goes slower near the ends\n",
        "        s = 1.5 gets very close to the \"cosine schedule\", i.e. (1-cos(pi*t))/2, i.e. sin^2(pi/2*x)\"\"\"\n",
        "    if s<0 or s>1.5: raise ValueError(f\"s={s} is out of bounds.\")\n",
        "    tw = 4*(1-s)*t**3 + 6*(s-1)*t**2 + (3-2*s)*t\n",
        "    if dt:                           # warped time-step requested; use derivative\n",
        "        return tw,  dt * 12*(1-s)*t**2 + 12*(s-1)*t + (3-2*s)\n",
        "    return tw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b77bff-e64a-41ac-86f2-b49a0e84ef0a",
      "metadata": {
        "cellView": "form",
        "id": "c1b77bff-e64a-41ac-86f2-b49a0e84ef0a"
      },
      "outputs": [],
      "source": [
        "# @title Code to viz parabola example\n",
        "from functools import partial\n",
        "\n",
        "parab   = lambda x: 4*(x-0.5)**2  # curve shape\n",
        "d_parab = lambda x: 8*(x-0.5)     # derivative\n",
        "ds      = lambda x: torch.sqrt(1 + d_parab(x)**2)  # differential arc length\n",
        "\n",
        "def calculate_total_arc_length(n=1000):\n",
        "    \"\"\"Calculate the total arc length of the parabola y = 4(x - 0.5)**2 from x=0 to x=1\"\"\"\n",
        "    x_values = torch.linspace(0, 1, n)\n",
        "    arc_length_values = ds(x_values)\n",
        "    total_arc_length = torch.trapz(arc_length_values, x_values)\n",
        "    return total_arc_length\n",
        "\n",
        "def fake_velocity_model(loc, t, speed=1.0):\n",
        "    \"\"\"For demo purposes only: Follow a parabolic path and move at unit speed\n",
        "    Compute the x and y components of the velocity along the parabola y = 4(x - 0.5)^2\"\"\"\n",
        "    x, y = loc[:, 0], loc[:, 1]\n",
        "    slope = d_parab(x)\n",
        "    direction = torch.stack([torch.ones_like(slope), slope], dim=1)\n",
        "    magnitude = torch.norm(direction, dim=1, keepdim=True)\n",
        "    unit_velocity = direction / magnitude\n",
        "    return unit_velocity*speed\n",
        "\n",
        "@torch.no_grad()\n",
        "def integrate_motion_along_parabola(\n",
        "        model, initial_points, n_steps=30, step_fn=fwd_euler_step, s=0.5,):\n",
        "    \"\"\"one-off integrator used only for this one visualization figure. don't use for anything else\"\"\"\n",
        "    current_points = initial_points.clone()\n",
        "    trajectories = [current_points.cpu().clone()]\n",
        "    ts = torch.linspace(0,1.0, n_steps)\n",
        "    ts = warp_time(ts, s=s)                # here's the time worpage\n",
        "    speed = calculate_total_arc_length()   # Total travel time is 1.0 so speed \"=\" distance\n",
        "    scaled_model = partial(model, speed=speed)\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_steps-1):\n",
        "            current_points = step_fn( scaled_model , current_points.clone(), ts[i],  ts[i+1]-ts[i])\n",
        "            trajectories.append(current_points.cpu().clone())\n",
        "    return torch.stack(trajectories)\n",
        "\n",
        "@torch.no_grad()\n",
        "def viz_parabola_with_steps(step_fn=fwd_euler_step, n_steps=28):\n",
        "    \"\"\"varies warp parameter s and integrates along a parabola\"\"\"\n",
        "    plt.close()\n",
        "    t_curve = torch.linspace(0,1,100)\n",
        "\n",
        "    n_t_points = n_steps # 28 if step_fn==fwd_euler_step else 6\n",
        "    t_points = torch.linspace(0,1,n_t_points)\n",
        "\n",
        "    n_s = 6    # number of different s values to show\n",
        "    fig, ax = plt.subplots(1, n_s, figsize=(n_s*2.8, 3))\n",
        "    plt.suptitle(f\"Integration scheme = {step_fn.__name__}\", fontsize=16, y=1.05)\n",
        "    initial_points = torch.tensor([[0,1]])                   # one point in the top left\n",
        "    for i, s in enumerate(torch.linspace(.25, 1.5, n_s)):   # warp time by different amounts via s parameter\n",
        "        ax[i].plot(t_curve, parab(t_curve))    # solid line showing path\n",
        "        traj = integrate_motion_along_parabola(fake_velocity_model, initial_points, n_steps=n_t_points,\n",
        "                    s=s, step_fn=step_fn).squeeze()\n",
        "        err_str = f\"\\nerror={F.mse_loss(parab(traj[:,0]),traj[:,1]):.3g}\"\n",
        "        ax[i].scatter(traj[:,0], traj[:,1], label=f's = {s:.2f}{err_str}', color=(wong_cmap*2)[i])\n",
        "\n",
        "        legend = ax[i].legend(loc='upper center', frameon=False, markerscale=0, handlelength=0, fontsize=12)\n",
        "        for text in legend.get_texts():\n",
        "            text.set_ha('center')\n",
        "\n",
        "        if abs(s-1.0) < 1e-6: ax[i].set_title('Even Spacing')\n",
        "\n",
        "    ax[0].set_title('More Points in Middle')\n",
        "    ax[-1].set_title('More Points at Ends')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "viz_parabola_with_steps(fm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6334e8f6-589c-497e-8b3d-8f3f5d1d4b5c",
      "metadata": {
        "id": "6334e8f6-589c-497e-8b3d-8f3f5d1d4b5c"
      },
      "source": [
        "While the results for $s=0.5$ are better than the others, we see that *none* of these examples make it all the way around the parabola (to the point (1,1))! If we're going to be using the flow matching model as a proxy for the true target data, we should have some confidence that it's actually \"getting to\" the target data.  We could add more points to the integration, but there's another way: upgrade the integration (i.e. sampling) operation to a higher order of accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a459a85e-90ee-4c85-8352-b97c3282f5d7",
      "metadata": {
        "id": "a459a85e-90ee-4c85-8352-b97c3282f5d7"
      },
      "source": [
        "###  Better Integration / Sampling\n",
        "\n",
        "While forward Euler is surprisingly popular in ML circles, those with simulation backgrounds eye it with suspicion: despite being being fast and easy to implement,  it's also highly inaccurate and can lead to instabilities. The poor accuracy may not be an issue when everything's an approximation anyway, but we can do a lot better.\n",
        "\n",
        "People who work with diffusion models know this, e.g. in [Katherine Crowson's k-diffusion package](https://github.com/crowsonkb/k-diffusion) offers a bevy of integration choices.  For here we'll just implement the popular 4th-order Runge-Kutta (RK4) scheme. It's more \"expensive\" than forward Euler in that each step requires 4 function evaluations instead of forward Euler's 1 step, and it requires some extra storage, but the advantages you gain in accuracy are seriously worth it (e.g., because you can take much longer steps in time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330a4fd7-68aa-4024-8380-3714e7da2ce7",
      "metadata": {
        "cellView": "form",
        "id": "330a4fd7-68aa-4024-8380-3714e7da2ce7"
      },
      "outputs": [],
      "source": [
        "# @title Code for 4th-order Runge-Kutta integration\"\n",
        "def rk4_step(f, # function that takes (t,y) and returns dy/dt, i.e. velocity\n",
        "             y, # current location\n",
        "             t, # current t value\n",
        "             dt, # requested time step size\n",
        "             ):\n",
        "    k1 =  f(y, t)\n",
        "    k2 =  f(y + dt*k1/2, t + dt/2)\n",
        "    k3 =  f(y + dt*k2/2, t + dt/2)\n",
        "    k4 =  f(y + dt*k3, t + dt)\n",
        "    return y + (dt/6)*(k1 + 2*k2 + 2*k3 + k4)\n",
        "\n",
        "viz_parabola_with_steps(step_fn=rk4_step, n_steps=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08588f6a-5a0d-4fd0-b47f-3b2fafcf5630",
      "metadata": {
        "id": "08588f6a-5a0d-4fd0-b47f-3b2fafcf5630"
      },
      "source": [
        "It's cool how the RK4 results, despite showing less error that the Euler results, actually involve *less* computational cost in terms of number of function evaluations, though the RK4 scheme needs 4 times the storage compared for forward Euler. (The good news is that no PyTorch gradients need to be stored; the integrator is only ever used when the model is in \"eval\" mode.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df5b9cf4-367e-4a1d-a002-9eeec64c2c85",
      "metadata": {
        "id": "df5b9cf4-367e-4a1d-a002-9eeec64c2c85"
      },
      "source": [
        "## \"ReFlow\" to Go Straight and Fast"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "524e3e35-bd7d-468c-aeba-e20292ac7b46",
      "metadata": {
        "id": "524e3e35-bd7d-468c-aeba-e20292ac7b46"
      },
      "source": [
        "When we train the student model, aka the rectified model, note that the \"target data\" will no longer be supplied by the true target data anymore.  Rather we will be using the trajectory endpoints integrated/generated using the teacher model, i.e. the pretrained flow model.  \n",
        "\n",
        "So.... how close of an approximation are those learned flow endpoints to the real thing?   We're going to be approximating an approximation, but how good is the original approximation?\n",
        "\n",
        "Let's take a look..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b789f33-22a5-4c10-8363-949645f858d2",
      "metadata": {
        "cellView": "form",
        "id": "8b789f33-22a5-4c10-8363-949645f858d2"
      },
      "outputs": [],
      "source": [
        "# @title Quick check of how our flow endpoints are looking\n",
        "pretrained_model = fm_model\n",
        "pretrained_model.eval()\n",
        "reflow_targets = integrate_path(pretrained_model, val_points.to(device), n_steps=8, step_fn=rk4_step, warp_fn=warp_time).cpu()\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(10,3))\n",
        "for i, [data, color, label] in enumerate(zip([val_points,   reflow_targets, target_samples],\n",
        "                                             [source_color, pred_color,     target_color],\n",
        "                                             ['Source Data', 'Learned Flow Endpoints', 'True Target Data'])):\n",
        "    ax[i].scatter(data[:,0], data[:,1], color=color, label=label, alpha=0.6)\n",
        "    ax[i].set_aspect('equal')\n",
        "    ax[i].set_title(label)\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b233c26-abef-442b-a020-588d65d1671a",
      "metadata": {
        "id": "0b233c26-abef-442b-a020-588d65d1671a"
      },
      "source": [
        "....ok, so we see the learned outputs are a bit different from the true data, but they're not bad.  Let's now train the \"reflow\" model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d930f9f-6636-4691-8f14-3404fd3b7430",
      "metadata": {
        "id": "3d930f9f-6636-4691-8f14-3404fd3b7430"
      },
      "source": [
        "### Train the Reflowed Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f45cbe-0699-43aa-9d56-a563306dd98a",
      "metadata": {
        "id": "c5f45cbe-0699-43aa-9d56-a563306dd98a"
      },
      "source": [
        "There's one small but crucial change from the previous training code to this one, namely what we use as target data:\n",
        "```python\n",
        "##  target_samples = create_target_data(batch_size)           # Previous \"random pairing\"\n",
        "target_samples = integrator(pretrained_model, source_samples) # Reflow!\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45ce783-17f7-48af-a8eb-2f211b237b2a",
      "metadata": {
        "cellView": "form",
        "id": "d45ce783-17f7-48af-a8eb-2f211b237b2a"
      },
      "outputs": [],
      "source": [
        "# @title Code for new Training loop w/ ReFlowed targets\n",
        "def train_reflow_model(model, pretrained_model=None,\n",
        "                          n_epochs=40, lr=0.001, batch_size=2048,\n",
        "                          status_every=1, viz_every=1, # in epochs\n",
        "                          new_points_every=1, # in steps\n",
        "                          warp_fn=warp_time,\n",
        "                          step_fn=rk4_step, # rk4 so we get high-quality outputs while reflowing\n",
        "                          ):\n",
        "    \"\"\"This is almost IDENTICAL to the previous training routine.\n",
        "        The difference is the change in \"target_samples\" via what the RF authors call \"ReFlow\":\n",
        "        Instead of (randomly) paring source points with points in the \"true target distribution\",\n",
        "        we use the pretrained/teacher model to integrate the source points to their (predicted) flow endpoints\n",
        "        and use THOSE as the \"target\" values.\n",
        "    \"\"\"\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    step, n_steps = 0, 100\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        pbar = tqdm(range(n_steps), leave=False)\n",
        "        for _ in pbar:\n",
        "            step += 1\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if step % new_points_every == 0:  # you could in theory not draw new points with each step, though we will.\n",
        "                source_samples = create_source_data(batch_size).to(device)\n",
        "                if pretrained_model:   # HERE is the ReFlow operation...\n",
        "                    target_samples = integrate_path(pretrained_model, source_samples, step_fn=rk4_step, warp_fn=warp_time, n_steps=20)\n",
        "                else:\n",
        "                    target_samples = create_target_data(batch_size) # this function also supports fm models from scratch\n",
        "\n",
        "            t = torch.rand(source_samples.size(0), 1).to(device) # random times for training\n",
        "            if warp_fn: t = warp_fn(t)  # time warp here (different from use in integrator!) helps focus \"coverage\" i.e. sampling the space\n",
        "\n",
        "            interpolated_samples = source_samples * (1 - t) + target_samples * t\n",
        "            v = model(interpolated_samples, t)\n",
        "            line_directions = target_samples - source_samples\n",
        "            loss = loss_fn(v, line_directions)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_description(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {loss.item():.4g}')\n",
        "\n",
        "        if (epoch + 1) % viz_every == 0:\n",
        "            model.eval()\n",
        "            clear_output(wait=True)  # Clear previous plots\n",
        "            viz(val_points, target_samples[:val_points.shape[0]], model)  # don't need rk4 for rect model viz b/c paths r straight\n",
        "            plt.show()\n",
        "            plt.close()  # Close the figure to free memory\n",
        "            model.train()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86aa01c1-a4b3-465b-b646-ca5f2fabd1a8",
      "metadata": {
        "id": "86aa01c1-a4b3-465b-b646-ca5f2fabd1a8"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "reflowed_model = copy.deepcopy(pretrained_model) # no need to train student from scratch, start from teacher's weights\n",
        "reflowed_model.train()\n",
        "\n",
        "reflowed_model = train_reflow_model(reflowed_model, pretrained_model=pretrained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826c08e1-2c18-4247-9dcf-58487ea40045",
      "metadata": {
        "id": "826c08e1-2c18-4247-9dcf-58487ea40045"
      },
      "source": [
        "Oooo, look how straight the trajectories are now!  Let's compare animations of the original flow matching model with the \"Reflowed\" model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16588c95-bba8-49a6-a550-aeded8893f9a",
      "metadata": {
        "id": "16588c95-bba8-49a6-a550-aeded8893f9a"
      },
      "outputs": [],
      "source": [
        "rect_eval = reflowed_model.eval()\n",
        "\n",
        "anim_file = None # \"images/particles_fm_vs_rf.mp4\"\n",
        "create_flow_animation(val_points.clone(), models=[pretrained_model, reflowed_model],\n",
        "        n_frames=50, titles=['Flow Matching','Reflowed Flow'], save_file=anim_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca2f1cc-8ae0-4ab3-88a0-04411fb6dd85",
      "metadata": {
        "id": "4ca2f1cc-8ae0-4ab3-88a0-04411fb6dd85"
      },
      "source": [
        "Notice how the flow matching trajectories on the left have the data moving inward a ways and then back out, whereas the reflowed trajectories move directly from start to finish with no backtracking.\n",
        "\n",
        "The next movie shows an animation of \"streamlines\" with arrows for the local vector field. Note how the shapes on the right change very little over time compared to those on the left. We'll say a bit more about that below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ff47a9-8e73-4b43-911e-793b0ff7d3cd",
      "metadata": {
        "cellView": "form",
        "id": "75ff47a9-8e73-4b43-911e-793b0ff7d3cd"
      },
      "outputs": [],
      "source": [
        "# @title Code to produce streamline animation (take a little while to run)\n",
        "@torch.no_grad()\n",
        "def create_streamline_animation(start_dist, model, model2=None, n_frames=50, show_points=False, titles=None,\n",
        "                                step_fn=fwd_euler_step,  # euler's ok for reflowed model bc/paths are straight\n",
        "                                save_file=None,\n",
        "                               ):\n",
        "    \"\"\"Create an animation showing distribution flow with streamplot background\"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    figsize = [5,5]\n",
        "    if titles is None:\n",
        "        titles = ['Flow Matching']\n",
        "        if model2: titles += ['Reflowed Model']\n",
        "    if model2:\n",
        "        figsize[0] *= 2\n",
        "    n_plots = 1 + (model2 is not None)\n",
        "    fig, ax = plt.subplots(1, n_plots, figsize=figsize)\n",
        "    if n_plots==1: ax = [ax]\n",
        "    plt.close()\n",
        "\n",
        "    end_dist, trajectories = integrate_path(model, start_dist.clone().to(device), n_steps=n_frames, step_fn=step_fn, warp_fn=warp_time, save_trajectories=True)\n",
        "    scatter = ax[0].scatter([], [], alpha=0.6, s=10, color=wong_pink, zorder=1)\n",
        "    if model2:\n",
        "        _, trajectories2 = integrate_path(model2, start_dist.clone().to(device), n_steps=n_frames, step_fn=step_fn, warp_fn=warp_time, save_trajectories=True)\n",
        "        scatter2 = ax[1].scatter([], [], alpha=0.6, s=10, color=wong_pink, zorder=1)\n",
        "\n",
        "    max_range = max( abs(start_dist).max().item(), abs(end_dist).max().item() )\n",
        "\n",
        "    for i in range(len(ax)):\n",
        "        ax[i].set_xlim((-max_range, max_range))\n",
        "        ax[i].set_ylim((-max_range, max_range))\n",
        "        ax[i].set_aspect('equal')\n",
        "        if titles: ax[i].set_title(titles[i])\n",
        "\n",
        "\n",
        "    # Create grid for streamplot\n",
        "    grid_dim = 50\n",
        "    x = np.linspace(-max_range, max_range, grid_dim)\n",
        "    y = np.linspace(-max_range, max_range, grid_dim)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Convert grid to torch tensor for model input\n",
        "    grid_points = torch.tensor(np.stack([X.flatten(), Y.flatten()], axis=1), dtype=torch.float32).to(device)\n",
        "    color = wong_pink if show_points else (0,0,0,0)\n",
        "\n",
        "    dt = 1.0 / n_frames\n",
        "\n",
        "    def init():\n",
        "        for i in range(len(ax)):\n",
        "            ax[i].clear()\n",
        "            ax[i].set_xlim((-max_range, max_range))\n",
        "            ax[i].set_ylim((-max_range, max_range))\n",
        "        scatter.set_offsets(np.c_[[], []])\n",
        "        if model2:\n",
        "                scatter.set_offsets(np.c_[[], []])\n",
        "                return (scatter,scatter2)\n",
        "        return (scatter,)\n",
        "\n",
        "    def animate(frame):\n",
        "        for i in range(len(ax)):\n",
        "            ax[i].clear()\n",
        "            ax[i].set_xlim((-max_range, max_range))\n",
        "            ax[i].set_ylim((-max_range, max_range))\n",
        "            if titles: ax[i].set_title(titles[i])\n",
        "            ax[i].set_xticks([])\n",
        "            ax[i].set_yticks([])\n",
        "            for spine in ['top','right','bottom','left']:\n",
        "                ax[i].spines[spine].set_visible(False)\n",
        "\n",
        "        # Update scatter plot\n",
        "        current = trajectories[frame]\n",
        "        scatter = ax[0].scatter(current[:, 0], current[:, 1], alpha=0.6, s=10, color=color, zorder=1)\n",
        "        if model2:\n",
        "            current2 = trajectories2[frame]\n",
        "            scatter2 = ax[i].scatter(current2[:, 0], current2[:, 1], alpha=0.6, s=10, color=color, zorder=1)\n",
        "\n",
        "        # Calculate vector field for current time\n",
        "        t = torch.ones(grid_points.size(0), 1) * (frame * dt)\n",
        "        t = warp_time(t).to(device)\n",
        "        velocities = model(grid_points, t).cpu()\n",
        "        U = velocities[:, 0].reshape(X.shape)\n",
        "        V = velocities[:, 1].reshape(X.shape)\n",
        "\n",
        "        x_points = np.linspace(-max_range, max_range, 15)\n",
        "        y_points = np.linspace(-max_range, max_range, 15)\n",
        "        X_arrows, Y_arrows = np.meshgrid(x_points, y_points)\n",
        "        start_points = np.column_stack((X_arrows.ravel(), Y_arrows.ravel()))\n",
        "        ax[0].streamplot(X, Y, U.numpy(), V.numpy(),\n",
        "             density=5,  # Controls line spacing\n",
        "             color=line_color, # (0, 0, 1, 0.7),\n",
        "             linewidth=0.8, maxlength=0.12,\n",
        "             start_points=start_points,  # This should give more arrows along paths\n",
        "             arrowsize=1.2,\n",
        "             arrowstyle='->')\n",
        "\n",
        "        if model2:\n",
        "            velocities2 = model2(grid_points, t).cpu()\n",
        "            U2 = velocities2[:, 0].reshape(X.shape)\n",
        "            V2 = velocities2[:, 1].reshape(X.shape)\n",
        "            start_points2 = np.column_stack((X_arrows.ravel(), Y_arrows.ravel()))\n",
        "            ax[1].streamplot(X, Y, U2.numpy(), V2.numpy(),\n",
        "                 density=5,  # Controls line spacing\n",
        "                 color=line_color, # (0, 0, 1, 0.7),\n",
        "                 linewidth=0.8, maxlength=0.12,\n",
        "                 start_points=start_points2,  # This should give more arrows along paths\n",
        "                 arrowsize=1.2,\n",
        "                 arrowstyle='->')\n",
        "\n",
        "\n",
        "        # Update particle positions\n",
        "        t = torch.ones(current.size(0), 1) * (frame * dt)\n",
        "        t, dtw = warp_time(t, dt=dt)\n",
        "        velocity = model(current.to(device), t.to(device)).cpu()\n",
        "        current = current + velocity * dtw\n",
        "        if model2:\n",
        "            velocity2 = model2(current2.to(device), t.to(device)).cpu()\n",
        "            current2 = current2 + velocity2 * dtw\n",
        "            return (scatter, scatter2,)\n",
        "        return (scatter,)\n",
        "\n",
        "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                                 frames=n_frames, interval=20, blit=False)\n",
        "\n",
        "    if save_file:\n",
        "        anim.save(save_file, writer='ffmpeg', fps=30)\n",
        "        return HTML(f\"\"\"<center><video height=\"350\" controls loop><source src=\"{save_file}\" type=\"video/mp4\">\n",
        "                      Your browser does not support the video tag.</video></center>\"\"\")\n",
        "    else:\n",
        "        rc('animation', html='jshtml')\n",
        "        return HTML(anim.to_jshtml())\n",
        "\n",
        "\n",
        "save_file = None # 'images/fm_vs_rf_streamvecs.mp4'\n",
        "create_streamline_animation(val_points, fm_model, model2=reflowed_model, n_frames=50, save_file=save_file)#, show_points=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd07c4dc-b3d6-4561-921f-c8f450268296",
      "metadata": {
        "id": "cd07c4dc-b3d6-4561-921f-c8f450268296"
      },
      "source": [
        "# Connecting with Other Models\n",
        "\n",
        "\n",
        "### From Dots to Images, Audio, etc..\n",
        "\n",
        "How to move on from 2D dots to things like images, text, audio,...etc? We need only consider that the dimensionality of the velocity model is the same as that of the data itself.  Put differently, one can regard the velocity model as supply a tiny \"change\" to the data, whatever form that data is in. And the \"straight line\" trajectory used during training? That's just linear interpolation between the (initially randomly-paired) source data and the target data.  So for images, we will get a \"velocity image\", which will tell us how to change the R,G,B value of every pixel in an image.  This is where U-Nets and Attention come in to play, to compute the \"image-to-image\" task of supplying a \"velocity image\" given an input image distribution (which may just be noise).   For audio, regardless of the representation, the velocity model will tell us how to slightly change the component values in that representation. We then just integrate all the little changes as we did with the dots.\n",
        "\n",
        "*  I recommend checking out an MNIST image example such as Tadao Yamaoka's [9]\n",
        "\n",
        "\n",
        "### Diffusion Models\n",
        "\n",
        "Diffusion-models, aka \"score-based models\" are similar to flow models in that the former also learn a vector field (the \"score function\") that serves to differentially transform the points in the sample.  The difference is that flow models are deterministic, whereas diffusion models are constantly injecting fresh noise, as if they are simulating actual Brownian motion [7] rather than the macroscopic flow.  To turn our flow model into a diffusion model, we could add \"jitter,\" i.e. inject noise at every step.  The variance of that jitter as a function of time would correspond directly to the \"noise schedule\" of diffusion models.  \n",
        "  \n",
        "\n",
        "\n",
        "### Optimal Transport\n",
        "\n",
        "Interesting observation: See how the Reflowed streamlines in the last movie are approximately stationary (i.e., time-independent)? This connects nicely with Optimal Transport theory, where the Benamou-Brenier formulation [10] (which has a diffusion-esque equation as on objective) shows that optimal mass transport paths follow constant-velocity geodesics in the Wasserstein metric space. This time-independence property emerges naturally when minimizing transport costs in simple metric spaces, as particles following straight-line paths at constant speeds achieve optimal transport between distributions.\n",
        "\n",
        "\n",
        "\n",
        "### Normalizing Flows\n",
        "\n",
        "Normalizing flows have the property that they preserve overall probability throughout the flow process. It turns out that, while this would seem to be a nice constraint to satisfy, it is unnecessary for \"getting the job done\" and can limit the expressiveness of the model. Note: Since I'm pushing a \"physics perspective,\" a similar property arises in the phase space flows of Hamiltonian mechanics, which preserve area elements ala Liousville's Theorem [11]. The connection between normalizing flows and Hamiltonian systems was applied to generative modeling in the \"Neural Hamiltonian Flows\" paper of ICLR 2020 [12], and continues in a recent NeurIPS 2024 poster-paper [13].[^3] Despite these fascinating connections, the exciting thing about flow-matching and rectified flows is that they seem to be effective even in the absence of the explicit conservation properties of normalizing flows and their relatives, and can thus be implemented quickly and simply.\n",
        "\n",
        "[^3]: Check out [Yilun Xu's](https://yilun-xu.com/) work for more on physics-inspired generative models.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfe758f-e804-4426-b2a4-15eb1be4d3ca",
      "metadata": {
        "id": "4bfe758f-e804-4426-b2a4-15eb1be4d3ca"
      },
      "source": [
        "# Summary\n",
        "\n",
        "We've seen that flow matching and rectified flows models can be conceptualized and even developed using some simple ideas from basic physics. This simplicy, coupled with their power and flexibility have fueled their popularity and even rise to state-of-the-art levels.  \n",
        "\n",
        "Hopefully, after having read this, you will be able to better follow the rapid progress in flow-based generative AI in terms of both scholarly and industry output, as well as to have the confidence to expand on these ideas for your own investigations!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431ca199-8229-48a9-b7b0-f2a239c00639",
      "metadata": {
        "id": "431ca199-8229-48a9-b7b0-f2a239c00639"
      },
      "source": [
        "# References\n",
        "\n",
        "[1]\n",
        "P. Esser et al., “Scaling rectified flow transformers for high-resolution image synthesis,” in 41st International Conference on Machine Learning, ICML, Vienna, Austria, 2024. Available: https://openreview.net/forum?id=FPnUhsQJ5B\n",
        "\n",
        "[2]\n",
        "X. Liu, C. Gong, and Q. Liu, “Flow straight and fast: Learning to generate and transfer data with rectified flow,” in 11th International Conference on Learning Representations (ICLR), 2023. Available: https://openreview.net/forum?id=XVjTT1nw5z\n",
        "\n",
        "[3]\n",
        "S. Lee, Z. Lin, and G. Fanti, “Improving the training of rectified flows.” 2024. Available: https://arxiv.org/abs/2405.20320\n",
        "\n",
        "[4]\n",
        "J.-B. Huang, “How I understand flow matching.” YouTube, 2024. Available: https://www.youtube.com/watch?v=DDq_pIfHqLs\n",
        "\n",
        "[5]\n",
        "T. Beier and S. Neely, “Feature-based image metamorphosis,” ACM SIGGRAPH Comput. Graph., vol. 26, no. 2, pp. 35–42, Jul. 1992, doi: 10.1145/142920.134003.\n",
        "\n",
        "[6]\n",
        "T. M. Abraham, “\"Flow matching and rectified flows are the same.” X.com, 2024. Available: https://x.com/iScienceLuvr/status/1766700945243881889\n",
        "\n",
        "[7]\n",
        "“Brownian motion - Wikipedia — en.wikipedia.org.” https://en.wikipedia.org/wiki/Brownian_motion.\n",
        "\n",
        "[8]\n",
        "Y. Song, P. Dhariwal, M. Chen, and I. Sutskever, “Consistency models.” 2023. Available: https://arxiv.org/abs/2303.01469\n",
        "\n",
        "[9]\n",
        "T. Yamaoka, “Image generation with rectified flow part 2 (learning MNIST using scratch implementation).” 2024. Available: https://tadaoyamaoka.hatenablog.com/entry/2024/09/29/163801\n",
        "\n",
        "[10]\n",
        "J.-D. Benamou and Y. Brenier, “A computational fluid mechanics solution to the Monge-Kantorovich mass transfer problem,” Numerische Mathematik, vol. 84, pp. 375–393, 2000, Available: https://api.semanticscholar.org/CorpusID:1100384\n",
        "\n",
        "[11]\n",
        "Wikipedia, “Liouville’s theorem (Hamiltonian) — Wikipedia, the free encyclopedia.” http://en.wikipedia.org/w/index.php?title=Liouville's%20theorem%20(Hamiltonian)&oldid=1233185478, 2024.\n",
        "\n",
        "[12]\n",
        "P. Toth, D. J. Rezende, A. Jaegle, S. Racanière, A. Botev, and I. Higgins, “Hamiltonian generative networks,” in International Conference on Learning Representations (ICLR), 2020. Available: https://openreview.net/forum?id=HJenn6VFvB\n",
        "\n",
        "[13]\n",
        "P. Holderrieth, Y. Xu, and T. Jaakkola, “Hamiltonian score matching and generative flows.” 2024. Available: https://arxiv.org/abs/2410.20470"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ca1aac0-1635-4afe-8112-830ecce836a2",
      "metadata": {
        "id": "8ca1aac0-1635-4afe-8112-830ecce836a2"
      },
      "source": [
        "---\n",
        "(c) 2024 Scott H. Hawley\n",
        "\n",
        "#### Acknowledgement  {.unnumbered}\n",
        "This work was graciously supported by Belmont University, Hyperstate Music AI, Razer Inc., and NVIDIA's Inception program. Much of this tutorial was hashed out through \"conversations\" with Claude 3.5 Sonnet.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1942de79-ca20-4581-aefd-fb23bbbc9f6a",
      "metadata": {
        "id": "1942de79-ca20-4581-aefd-fb23bbbc9f6a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}