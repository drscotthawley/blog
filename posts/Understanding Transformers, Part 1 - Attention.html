<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Scott H. Hawley">
<meta name="dcterms.date" content="2023-08-11">
<meta name="description" content="Focusing attention on Attention">

<title>blog - Understanding Transfomers, Part 1: Attention</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="blog - Understanding Transfomers, Part 1: Attention">
<meta name="twitter:description" content="Focusing attention on Attention">
<meta name="twitter:image" content="https://drscotthawley.github.io/blog/posts/images/TransformerOvalInOut.gif">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/drscotthawley" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/drscotthawley" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Understanding Transfomers, Part 1: Attention</h1>
                  <div>
        <div class="description">
          Focusing attention on Attention
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">nlp</div>
                <div class="quarto-category">architectures</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Scott H. Hawley </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 11, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preface" id="toc-preface" class="nav-link active" data-scroll-target="#preface">Preface</a></li>
  <li><a href="#forming-intuition" id="toc-forming-intuition" class="nav-link" data-scroll-target="#forming-intuition">Forming Intuition</a>
  <ul class="collapse">
  <li><a href="#weighted-averaging" id="toc-weighted-averaging" class="nav-link" data-scroll-target="#weighted-averaging">Weighted Averaging</a></li>
  </ul></li>
  <li><a href="#history-a-little-context" id="toc-history-a-little-context" class="nav-link" data-scroll-target="#history-a-little-context">History: A Little Context</a></li>
  <li><a href="#video-i-wrote-a-song" id="toc-video-i-wrote-a-song" class="nav-link" data-scroll-target="#video-i-wrote-a-song">Video: I Wrote A Song</a></li>
  <li><a href="#making-it-mathematical" id="toc-making-it-mathematical" class="nav-link" data-scroll-target="#making-it-mathematical">Making it Mathematical</a>
  <ul class="collapse">
  <li><a href="#similarity" id="toc-similarity" class="nav-link" data-scroll-target="#similarity">Similarity</a></li>
  </ul></li>
  <li><a href="#trying-it-out" id="toc-trying-it-out" class="nav-link" data-scroll-target="#trying-it-out">Trying it Out</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/TransformerOvalInOut.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">(GIF animation, zooming in on Attention part of model diagram)</figcaption>
</figure>
</div>
<p>— work in progress. not ready yet —</p>
<section id="preface" class="level1">
<h1>Preface</h1>
<p>Transformer neural network models finally “clicked” for me this summer! For 4 years, I’d felt confused about them despite having done a <em>lot</em> of study (see #References). They seem to have so many “moving parts,” so the complexity of the model was daunting for me (and apparently many others).</p>
<p>What finally helped was watching Andrej Karpathy’s excellent YouTube tutorial <span class="citation" data-cites="andrej_karpathy_lets_2023"><a href="#ref-andrej_karpathy_lets_2023" role="doc-biblioref">[1]</a></span> for the <em>second time</em>, when I noticed he homed in on the Attention part of the model and explained it as being a <em>weighted average of words.</em> I believe that if you grasp that part, then everything else about the Transformer is just “bells and whistles” that make it work better.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Throughout this tutorial I will use the phrase “Attention is just…” to share different perspectives that have helped me understand.</p>
</div>
</div>
</section>
<section id="forming-intuition" class="level1">
<h1>Forming Intuition</h1>
<p>Certain parts of an input matter more than others. For example, when you look at an image, you probably focus on objects in the foreground more than the background. For example, in this picture, most people (and AI systems!) will focus attention on the dog:</p>
<div id="fig-doggie" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/doggie_vit_attn_map.png" width="96%" align="left" class="figure-img"></p>
<figcaption class="figure-caption"><strong>Figure</strong>&nbsp;1<strong>.</strong> Example of attention being given to a foreground object, like this cute doggy! In right image, the background is darkened compared to the foreground, indicating that the foreground is receiving more attention than the background. (Source: Eunkwang Jeon, <a href="https://github.com/jeonsworld/ViT-pytorch">ViT-pytorch</a>)</figcaption>
</figure>
</div>
<p>Alternatively, when you’re reading or listening to a speaker, certain words carry more weight than others and contribute differently to the meaning formed in your mind. Consider the following sentence:</p>
<blockquote class="blockquote">
<p>“Please go to the store and get some milk.”</p>
</blockquote>
<p>If you’re trying understand the command being given, the words “go”, “store”, “get”, and “milk” probably matter the most to you. If what you’re interested in is the <em>tone</em> (e.g.&nbsp;“is the speaker being polite?”) then probably the “Please” would matter most.</p>
<p>Since the topic of Attention often comes up in the context of Natural Language Processing (NLP), we’ll stick to text for this lesson, but know that “<a href="https://paperswithcode.com/method/vision-transformer">Vision Transformers</a>” for image processing are definitely a thing.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Attention is just a way to give certain parts of an input more weight than others.</p>
</div>
</div>
<p>On computers, the way we often emphasize certain parts of an array more than others is to multiply them by another array that has the “weights” to be assigned. In some other contexts, the “weights” array may be also called a “mask”, such as a “hard mask” of 1’s and 0’s to turn on or off parts of the array, or a “soft mask” with floating-point values to emphasize certain elements.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Attention is just a soft mask.</p>
</div>
</div>
<p>Let’s use the sample sentence above, and <em>make up</em> some mask weights to stress the relative importants of different words. We’ll display the weights a colorbar to visualize their magnitude (darker= more weight):</p>
<div class="cell">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML, display</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">input</span> <span class="op">=</span> <span class="st">"Please go to the store and get some milk"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> <span class="bu">input</span>.split()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [<span class="fl">0.5</span>,<span class="fl">.9</span>,<span class="fl">0.1</span>,<span class="fl">0.0</span>,<span class="fl">.8</span>,<span class="fl">0.1</span>,<span class="fl">.93</span>,<span class="fl">0.1</span>,<span class="fl">.98</span>] </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">"word"</span>:words,<span class="st">"weight"</span>:weights})</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>display(df.set_index(<span class="st">'word'</span>).T.style.background_gradient(vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>).<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>).hide())</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sum of mask weights = </span><span class="sc">{</span>mask<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">:.3g}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="word-weights-0" class="cell-output cell-output-display">
<style type="text/css">
#T_8620d_row0_col0 {
  background-color: #73a9cf;
  color: #f1f1f1;
}
#T_8620d_row0_col1 {
  background-color: #045382;
  color: #f1f1f1;
}
#T_8620d_row0_col2, #T_8620d_row0_col5, #T_8620d_row0_col7 {
  background-color: #f0eaf4;
  color: #000000;
}
#T_8620d_row0_col3 {
  background-color: #fff7fb;
  color: #000000;
}
#T_8620d_row0_col4 {
  background-color: #0567a2;
  color: #f1f1f1;
}
#T_8620d_row0_col6 {
  background-color: #034a74;
  color: #f1f1f1;
}
#T_8620d_row0_col8 {
  background-color: #023d60;
  color: #f1f1f1;
}
</style>

<table id="T_8620d" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th id="T_8620d_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Please</th>
<th id="T_8620d_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">go</th>
<th id="T_8620d_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">to</th>
<th id="T_8620d_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">the</th>
<th id="T_8620d_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">store</th>
<th id="T_8620d_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">and</th>
<th id="T_8620d_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">get</th>
<th id="T_8620d_level0_col7" class="col_heading level0 col7" data-quarto-table-cell-role="th">some</th>
<th id="T_8620d_level0_col8" class="col_heading level0 col8" data-quarto-table-cell-role="th">milk</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_8620d_row0_col0" class="data row0 col0">0.500</td>
<td id="T_8620d_row0_col1" class="data row0 col1">0.900</td>
<td id="T_8620d_row0_col2" class="data row0 col2">0.100</td>
<td id="T_8620d_row0_col3" class="data row0 col3">0.000</td>
<td id="T_8620d_row0_col4" class="data row0 col4">0.800</td>
<td id="T_8620d_row0_col5" class="data row0 col5">0.100</td>
<td id="T_8620d_row0_col6" class="data row0 col6">0.930</td>
<td id="T_8620d_row0_col7" class="data row0 col7">0.100</td>
<td id="T_8620d_row0_col8" class="data row0 col8">0.980</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Sum of mask weights = 4.41</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the above example, I made up a weight of zero for “the” because it really doesn’t matter. The meaning of the sentence would still be unambiguous without “the”. We’ll use this trick of setting some weights to zero later on when we talk about “Masked Attention” for the Decoder part of the Transformer.</p>
</div>
</div>
<section id="weighted-averaging" class="level3">
<h3 class="anchored" data-anchor-id="weighted-averaging">Weighted Averaging</h3>
<p>We’ll make it so that the weights all add up to one. If all <span class="math inline">\(N\)</span> words were weighted equally, the weight values would all be <span class="math inline">\(1/N\)</span>. For other weighting schemes, we divide the mask weights by their sum to get our attention weights. For the example sentence above, dividing by the sum gives us:</p>
<div class="cell">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>attention <span class="op">=</span> mask<span class="op">/</span>mask.<span class="bu">sum</span>()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">"word"</span>:words,<span class="st">"weight"</span>:attention})</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>display(df.set_index(<span class="st">'word'</span>).T.style.background_gradient(vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="fl">.22</span>).<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">3</span>).hide())</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sum of attention weights = </span><span class="sc">{</span>attention<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">:.3g}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="word-weights-1" class="cell-output cell-output-display">
<style type="text/css">
#T_c8d6a_row0_col0 {
  background-color: #97b7d7;
  color: #000000;
}
#T_c8d6a_row0_col1 {
  background-color: #034b76;
  color: #f1f1f1;
}
#T_c8d6a_row0_col2 {
  background-color: #dad9ea;
  color: #000000;
}
#T_c8d6a_row0_col3 {
  background-color: #fff7fb;
  color: #000000;
}
#T_c8d6a_row0_col4 {
  background-color: #04629a;
  color: #f1f1f1;
}
#T_c8d6a_row0_col5, #T_c8d6a_row0_col7 {
  background-color: #f0eaf4;
  color: #000000;
}
#T_c8d6a_row0_col6 {
  background-color: #034369;
  color: #f1f1f1;
}
#T_c8d6a_row0_col8 {
  background-color: #023858;
  color: #f1f1f1;
}
</style>

<table id="T_c8d6a" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th id="T_c8d6a_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Please</th>
<th id="T_c8d6a_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">go</th>
<th id="T_c8d6a_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">to</th>
<th id="T_c8d6a_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">the</th>
<th id="T_c8d6a_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">store</th>
<th id="T_c8d6a_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">and</th>
<th id="T_c8d6a_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">get</th>
<th id="T_c8d6a_level0_col7" class="col_heading level0 col7" data-quarto-table-cell-role="th">some</th>
<th id="T_c8d6a_level0_col8" class="col_heading level0 col8" data-quarto-table-cell-role="th">milk</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_c8d6a_row0_col0" class="data row0 col0">0.091</td>
<td id="T_c8d6a_row0_col1" class="data row0 col1">0.204</td>
<td id="T_c8d6a_row0_col2" class="data row0 col2">0.045</td>
<td id="T_c8d6a_row0_col3" class="data row0 col3">0.000</td>
<td id="T_c8d6a_row0_col4" class="data row0 col4">0.181</td>
<td id="T_c8d6a_row0_col5" class="data row0 col5">0.023</td>
<td id="T_c8d6a_row0_col6" class="data row0 col6">0.211</td>
<td id="T_c8d6a_row0_col7" class="data row0 col7">0.023</td>
<td id="T_c8d6a_row0_col8" class="data row0 col8">0.222</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Sum of attention weights = 1</code></pre>
</div>
</div>
<p>When we convert the word strings to numbers (later), we will weight them appropriately. These weights are <em>literally</em> the attention. To put it differently:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Attention is just a weighted average of inputs.</p>
</div>
</div>
</section>
</section>
<section id="history-a-little-context" class="level1">
<h1>History: A Little Context</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Attention is just a weighted Bag of Words.</p>
</div>
</div>
</section>
<section id="video-i-wrote-a-song" class="level1">
<h1>Video: I Wrote A Song</h1>
<div class="cell">
<div class="cell-output cell-output-display">

<iframe width="560" height="315" src="https://www.youtube.com/embed/W65eENFUM_0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</div>
</div>
</section>
<section id="making-it-mathematical" class="level1">
<h1>Making it Mathematical</h1>
<section id="similarity" class="level2">
<h2 class="anchored" data-anchor-id="similarity">Similarity</h2>
</section>
</section>
<section id="trying-it-out" class="level1">
<h1>Trying it Out</h1>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>I recommend any of these the following. Seriously, I studied all of these and they’re great. Things just didn’t “click” for me until late in life I guess. LOL.</p>
<p>My trajectory was first the original paper<span class="citation" data-cites="aiayn"><a href="#ref-aiayn" role="doc-biblioref">[2]</a></span>, then Jay Alammar’s “The Illustrated Transformer” <span class="citation" data-cites="alammar_illustrated"><a href="#ref-alammar_illustrated" role="doc-biblioref">[3]</a></span>, then the Coursera course <span class="citation" data-cites="coursera"><a href="#ref-coursera" role="doc-biblioref">[4]</a></span> co-taught by one of the original Transformer paper authors, then Brendan Rohrer’s great post <span class="citation" data-cites="rohrer"><a href="#ref-rohrer" role="doc-biblioref">[5]</a></span>, then Jeremy Jordan’s tutorial <span class="citation" data-cites="jeremyj_transformers"><a href="#ref-jeremyj_transformers" role="doc-biblioref">[6]</a></span>. Then a couple years later Karpathy’s video <span class="citation" data-cites="andrej_karpathy_lets_2023"><a href="#ref-andrej_karpathy_lets_2023" role="doc-biblioref">[1]</a></span>, with a follow-up of CodeEmporiums’s video <span class="citation" data-cites="codeemporium"><a href="#ref-codeemporium" role="doc-biblioref">[7]</a></span>.</p>
<p>I also recommend Daniel Dugas’ “GPT on a Napkin” <span class="citation" data-cites="dugas_gpt_napkin"><a href="#ref-dugas_gpt_napkin" role="doc-biblioref">[8]</a></span>, but didn’t learn of it until later.</p>
<div id="refs" class="references csl-bib-body" role="list">
<div id="ref-andrej_karpathy_lets_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">A. Karpathy, <span>“Let’s build <span>GPT</span>: From scratch, in code, spelled out.”</span> Jan. 2023. Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">https://www.youtube.com/watch?v=kCc8FmEb1nY</a></div>
</div>
<div id="ref-aiayn" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">A. Vaswani <em>et al.</em>, <span>“Attention is <span>All</span> you <span>Need</span>,”</span> in <em>Advances in <span>Neural</span> <span>Information</span> <span>Processing</span> <span>Systems</span></em>, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., Curran Associates, Inc., 2017. Available: <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a></div>
</div>
<div id="ref-alammar_illustrated" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">J. Alammar, <span>“The <span>Illustrated</span> <span>Transformer</span>.”</span> Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a></div>
</div>
<div id="ref-coursera" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Y. B. Mourri and Ł. Kaiser, <span>“Natural <span>Language</span> <span>Processing</span> with <span>Attention</span> <span>Models</span>,”</span> <em>Coursera</em>. Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://www.coursera.org/learn/attention-models-in-nlp">https://www.coursera.org/learn/attention-models-in-nlp</a></div>
</div>
<div id="ref-rohrer" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">B. Rohrer, <span>“Transformers from <span>Scratch</span>.”</span> Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://e2eml.school/transformers.html">https://e2eml.school/transformers.html</a></div>
</div>
<div id="ref-jeremyj_transformers" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">J. Jordan, <span>“Understanding the <span>Transformer</span> architecture for neural networks,”</span> <em>Jeremy Jordan</em>. May 2023. Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://www.jeremyjordan.me/transformer-architecture/">https://www.jeremyjordan.me/transformer-architecture/</a></div>
</div>
<div id="ref-codeemporium" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">CodeEmporium, <span>“Transformer <span>Decoder</span> coded from scratch.”</span> Mar. 2023. Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://www.youtube.com/watch?v=MqDehUoMk-E">https://www.youtube.com/watch?v=MqDehUoMk-E</a></div>
</div>
<div id="ref-dugas_gpt_napkin" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">D. Dugas, <span>“The <span>GPT</span>-3 <span>Architecture</span>, on a <span>Napkin</span>.”</span> Accessed: Aug. 10, 2023. [Online]. Available: <a href="https://dugas.ch/artificial_curiosity/GPT_architecture.html">https://dugas.ch/artificial_curiosity/GPT_architecture.html</a></div>
</div>
</div>
<hr>
<p>(c) 2023 Scott H. Hawley</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>